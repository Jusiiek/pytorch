{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78180b70b342d7bc",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8798c13fced7ab9a",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html#sklearn.datasets.load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61f66f246c67a7ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T19:53:48.799776Z",
     "start_time": "2024-07-25T19:53:30.747801Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-lightning\n",
      "  Downloading pytorch_lightning-2.3.3-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: numpy>=1.17.2 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from pytorch-lightning) (1.26.3)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from pytorch-lightning) (2.3.1+cu118)\n",
      "Collecting tqdm>=4.57.0 (from pytorch-lightning)\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.6 kB ? eta -:--:--\n",
      "     ------- -------------------------------- 10.2/57.6 kB ? eta -:--:--\n",
      "     -------------------------------------- 57.6/57.6 kB 751.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: PyYAML>=5.4 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from pytorch-lightning) (6.0.1)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2024.2.0)\n",
      "Collecting torchmetrics>=0.7.0 (from pytorch-lightning)\n",
      "  Downloading torchmetrics-1.4.0.post0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from pytorch-lightning) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from pytorch-lightning) (4.12.2)\n",
      "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning)\n",
      "  Downloading lightning_utilities-0.11.6-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>=2022.5.0->pytorch-lightning)\n",
      "  Downloading aiohttp-3.9.5-cp311-cp311-win_amd64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (65.5.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from torch>=2.0.0->pytorch-lightning) (3.13.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from torch>=2.0.0->pytorch-lightning) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from torch>=2.0.0->pytorch-lightning) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from torch>=2.0.0->pytorch-lightning) (3.1.4)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from torch>=2.0.0->pytorch-lightning) (2021.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from tqdm>=4.57.0->pytorch-lightning) (0.4.6)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (23.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning)\n",
      "  Downloading frozenlist-1.4.1-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning)\n",
      "  Downloading multidict-6.0.5-cp311-cp311-win_amd64.whl.metadata (4.3 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning)\n",
      "  Downloading yarl-1.9.4-cp311-cp311-win_amd64.whl.metadata (32 kB)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=2.0.0->pytorch-lightning) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=2.0.0->pytorch-lightning) (2021.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from jinja2->torch>=2.0.0->pytorch-lightning) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from sympy->torch>=2.0.0->pytorch-lightning) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.7)\n",
      "Downloading pytorch_lightning-2.3.3-py3-none-any.whl (812 kB)\n",
      "   ---------------------------------------- 0.0/812.3 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 61.4/812.3 kB 3.4 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 71.7/812.3 kB 2.0 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 71.7/812.3 kB 2.0 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 204.8/812.3 kB 1.6 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 245.8/812.3 kB 1.2 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 307.2/812.3 kB 1.2 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 368.6/812.3 kB 1.2 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 368.6/812.3 kB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 532.5/812.3 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 583.7/812.3 kB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 634.9/812.3 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 696.3/812.3 kB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 768.0/812.3 kB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 778.2/812.3 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  798.7/812.3 kB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 812.3/812.3 kB 1.2 MB/s eta 0:00:00\n",
      "Downloading lightning_utilities-0.11.6-py3-none-any.whl (26 kB)\n",
      "Downloading torchmetrics-1.4.0.post0-py3-none-any.whl (868 kB)\n",
      "   ---------------------------------------- 0.0/868.8 kB ? eta -:--:--\n",
      "   - -------------------------------------- 30.7/868.8 kB 1.3 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 92.2/868.8 kB 1.3 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 133.1/868.8 kB 1.1 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 194.6/868.8 kB 1.2 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 245.8/868.8 kB 1.3 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 317.4/868.8 kB 1.2 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 368.6/868.8 kB 1.2 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 399.4/868.8 kB 1.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 471.0/868.8 kB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 491.5/868.8 kB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 563.2/868.8 kB 1.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 604.2/868.8 kB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 655.4/868.8 kB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 686.1/868.8 kB 1.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 737.3/868.8 kB 1.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 768.0/868.8 kB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 819.2/868.8 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 868.8/868.8 kB 1.1 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.3 kB ? eta -:--:--\n",
      "   -------------------- ------------------- 41.0/78.3 kB 991.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 78.3/78.3 kB 1.1 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.9.5-cp311-cp311-win_amd64.whl (370 kB)\n",
      "   ---------------------------------------- 0.0/370.8 kB ? eta -:--:--\n",
      "   ---- ----------------------------------- 41.0/370.8 kB 1.9 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 92.2/370.8 kB 1.1 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 143.4/370.8 kB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 204.8/370.8 kB 1.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 276.5/370.8 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 317.4/370.8 kB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 370.8/370.8 kB 1.2 MB/s eta 0:00:00\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.4.1-cp311-cp311-win_amd64.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.5/50.5 kB 1.3 MB/s eta 0:00:00\n",
      "Downloading multidict-6.0.5-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Downloading yarl-1.9.4-cp311-cp311-win_amd64.whl (76 kB)\n",
      "   ---------------------------------------- 0.0/76.7 kB ? eta -:--:--\n",
      "   ---------------- ----------------------- 30.7/76.7 kB 660.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 76.7/76.7 kB 1.1 MB/s eta 0:00:00\n",
      "Installing collected packages: tqdm, multidict, lightning-utilities, frozenlist, yarl, aiosignal, torchmetrics, aiohttp, pytorch-lightning\n",
      "Successfully installed aiohttp-3.9.5 aiosignal-1.3.1 frozenlist-1.4.1 lightning-utilities-0.11.6 multidict-6.0.5 pytorch-lightning-2.3.3 torchmetrics-1.4.0.post0 tqdm-4.66.4 yarl-1.9.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.utilities.types import OptimizerLRScheduler\n",
    "!pip install pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "id": "a42a59cd4c37c0eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T17:19:22.734487Z",
     "start_time": "2024-07-31T17:19:18.995488Z"
    }
   },
   "source": [
    "from sklearn.datasets import load_digits"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "52d3f02100db5438",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T17:19:22.776497Z",
     "start_time": "2024-07-31T17:19:22.734999Z"
    }
   },
   "source": [
    "data = load_digits().data"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "fbe626350a6016ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T17:19:22.784817Z",
     "start_time": "2024-07-31T17:19:22.777532Z"
    }
   },
   "source": [
    "data.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "453de6fc7ebc9dd5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T17:19:22.792507Z",
     "start_time": "2024-07-31T17:19:22.787379Z"
    }
   },
   "source": [
    "data[0]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n",
       "       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n",
       "       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n",
       "        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n",
       "       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "c0668291874ac612",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T17:19:22.815172Z",
     "start_time": "2024-07-31T17:19:22.794045Z"
    }
   },
   "source": [
    "targets = load_digits().target"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "88773ecb6c131185",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T17:19:22.820302Z",
     "start_time": "2024-07-31T17:19:22.816209Z"
    }
   },
   "source": [
    "targets.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "5806d7ae39fa2ed6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T17:19:22.831565Z",
     "start_time": "2024-07-31T17:19:22.820826Z"
    }
   },
   "source": [
    "targets[0]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "72b2bd8cfa3d5480",
   "metadata": {},
   "source": [
    "### Split data into training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8bed7465e0aced",
   "metadata": {},
   "source": [
    "to split data into training and testing use `train_test_split()` function from sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4173acae2fc280c3",
   "metadata": {},
   "source": [
    "Parameters `stratify` will ensure the same distribution of data in the training and testing sets, in our case we want the distribution of classes to be the same in both sets, so we specify `stratify = traget` which will ensure an equal distribution of data with respect to the target variable"
   ]
  },
  {
   "cell_type": "code",
   "id": "1516dcc8d3af0169",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T17:19:23.153451Z",
     "start_time": "2024-07-31T17:19:22.832080Z"
    }
   },
   "source": [
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "551c070f304a3857",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T17:19:23.160158Z",
     "start_time": "2024-07-31T17:19:23.153967Z"
    }
   },
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(data, targets, test_size=0.2, stratify=targets)"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "649848c29d4fff92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T17:19:23.166392Z",
     "start_time": "2024-07-31T17:19:23.162214Z"
    }
   },
   "source": [
    "train_X.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1437, 64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "b43f982803c1aafd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T17:19:23.172069Z",
     "start_time": "2024-07-31T17:19:23.167411Z"
    }
   },
   "source": [
    "train_X[0]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  9., 15., 13.,  0.,  0.,  0.,  0.,  5., 14.,  7., 13.,\n",
       "        2.,  0.,  0.,  0., 12., 10.,  1., 13.,  0.,  0.,  0.,  0.,  4.,\n",
       "        7.,  6., 11.,  0.,  0.,  0.,  0.,  0.,  0., 10.,  6.,  0.,  0.,\n",
       "        0.,  0.,  0.,  1., 15.,  0.,  0.,  0.,  0.,  0.,  0.,  9., 11.,\n",
       "        0.,  6.,  5.,  0.,  0.,  0., 11., 16., 16., 16., 16.,  3.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "72689135c6ecfec0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T17:19:23.178237Z",
     "start_time": "2024-07-31T17:19:23.172591Z"
    }
   },
   "source": [
    "test_X.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "2671e0dcd3f6827d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T17:19:23.184539Z",
     "start_time": "2024-07-31T17:19:23.179248Z"
    }
   },
   "source": [
    "train_X[1]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1., 14., 16., 12.,  0.,  0.,  0.,  0.,  5., 16.,  9., 16.,\n",
       "        6.,  0.,  0.,  0.,  3., 11.,  0., 14.,  9.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0., 10., 10.,  0.,  0.,  0.,  0.,  0.,  0., 14., 10.,  0.,\n",
       "        0.,  0.,  0.,  0., 10., 16.,  5.,  0.,  0.,  0.,  2., 15., 16.,\n",
       "       14.,  8., 12.,  2.,  0.,  0., 11., 16., 16., 16., 15.,  5.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T17:19:45.203637Z",
     "start_time": "2024-07-31T17:19:45.198528Z"
    }
   },
   "cell_type": "code",
   "source": "train_y",
   "id": "5a926ae6630cc21b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 8, ..., 8, 9, 4])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "b8767ed235eb7e47",
   "metadata": {},
   "source": [
    "## Datamodule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e16b8b39cbb9f2",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "id": "1d456e2431b4d605",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T17:20:00.549113Z",
     "start_time": "2024-07-31T17:19:52.207933Z"
    }
   },
   "source": [
    "from torch.utils.data import Dataset\n",
    "import pytorch_lightning as pl"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "e707c9626324453f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T17:20:00.554727Z",
     "start_time": "2024-07-31T17:20:00.550640Z"
    }
   },
   "source": [
    "class DigitsDataset(Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx] / 255\n",
    "        y = self.targets[idx]\n",
    "        \n",
    "        return x, y"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "id": "8f60d4df86350b41",
   "metadata": {},
   "source": [
    "## Datamodule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1e0e8abcb8f2ac",
   "metadata": {},
   "source": [
    "https://pytorch-lightning.readthedocs.io/en/stable/data/datamodule.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eafc35ce8bf7ee4",
   "metadata": {},
   "source": [
    "DataModule is a class that combines all the necessary functions to create data sets.\n",
    "\n",
    "`prepare_data` - downloads/loads data\n",
    "\n",
    "`setup` - divides data into training and test data\n",
    "\n",
    "`train_dataloader` and `val_dataloader` - return appropriate dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "id": "a9ba0eea256c98c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T17:20:00.561956Z",
     "start_time": "2024-07-31T17:20:00.556252Z"
    }
   },
   "source": [
    "from torch.utils.data import DataLoader"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "39cbbeff06cd2b15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T17:20:25.161273Z",
     "start_time": "2024-07-31T17:20:25.156550Z"
    }
   },
   "source": [
    "class DigitsDatamodule(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size = 32):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        self.data = load_digits().data\n",
    "        self.targets = load_digits().target\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        self.train_X, self.test_X, self.train_y, self.test_y = train_test_split(\n",
    "            self.data,\n",
    "            self.targets,\n",
    "            train_size=0.8,\n",
    "            stratify=self.targets\n",
    "        )\n",
    "        \n",
    "        self.train_dataset = DigitsDataset(self.train_X, self.train_y)\n",
    "        self.test_dataset = DigitsDataset(self.test_X, self.test_y)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=True)\n"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "id": "8ebe41d343ee856a",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "id": "7d7120aeb18db7fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T17:20:25.905279Z",
     "start_time": "2024-07-31T17:20:25.901710Z"
    }
   },
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "id": "478952806c4632bb",
   "metadata": {},
   "source": [
    "https://pytorch-lightning.readthedocs.io/en/stable/starter/converting.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d12bc1333c0fca",
   "metadata": {},
   "source": [
    "The `LightningModule` class combines the definitions of the model and the way it is trained\n",
    "\n",
    "`__init__` - contains definitions of layers used in the model\n",
    "\n",
    "`forward` - contains definitions of how the input passes through all layers\n",
    "\n",
    "`configure_optimizers` - creates and returns an optimizer\n",
    "\n",
    "`training_step` - implements model training from the perspective of one batch\n",
    "\n",
    "`validation_step` - implements model validation from the perspective of one batch"
   ]
  },
  {
   "cell_type": "code",
   "id": "5286c4d837698438",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T17:20:44.915288Z",
     "start_time": "2024-07-31T17:20:44.908062Z"
    }
   },
   "source": [
    "class DigitsModel(pl.LightningModule):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.loss_function = nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size, 100)\n",
    "        self.fc2 = nn.Linear(100, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        if not self.training:\n",
    "            out = F.softmax(out, dim=1)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters())\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch # returns x and y\n",
    "        outputs = self.forward(inputs.float()) # prediction\n",
    "        loss = self.loss_function(outputs, labels.long())\n",
    "        \n",
    "        self.log('train_loss', loss)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch # returns x and y\n",
    "        outputs = self.forward(inputs.float()) # prediction\n",
    "        loss = self.loss_function(outputs, labels)\n",
    "        \n",
    "        self.log('val_loss', loss)\n"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "id": "88a187c11949bd65",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329a60150df146dc",
   "metadata": {},
   "source": [
    "Create a datamodule - it contains a training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "id": "ab2b5bc576bc5869",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T17:20:55.001056Z",
     "start_time": "2024-07-31T17:20:54.997872Z"
    }
   },
   "source": [
    "data_module = DigitsDatamodule()"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "745931bcd7dcb56b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T17:20:55.902470Z",
     "start_time": "2024-07-31T17:20:55.866450Z"
    }
   },
   "source": [
    "data_module.prepare_data()"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "f5b3aa89b7af00e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T17:20:56.376859Z",
     "start_time": "2024-07-31T17:20:56.370761Z"
    }
   },
   "source": [
    "data_module.setup()"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "id": "b8af78abf119e475",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T17:20:57.244177Z",
     "start_time": "2024-07-31T17:20:57.224413Z"
    }
   },
   "source": [
    "print(next(iter(data_module.train_dataloader()))[0].shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64])\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "id": "c8374adf0694f162",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T17:20:59.546956Z",
     "start_time": "2024-07-31T17:20:59.542225Z"
    }
   },
   "source": [
    "print(next(iter(data_module.train_dataloader()))[1].shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32])\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "id": "ed49b0f045b097ca",
   "metadata": {},
   "source": [
    "Create a model - it contains the training logic"
   ]
  },
  {
   "cell_type": "code",
   "id": "2d1c0d8a84746220",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T17:21:04.820734Z",
     "start_time": "2024-07-31T17:21:04.812505Z"
    }
   },
   "source": [
    "model = DigitsModel(64, 10)"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "id": "b94c9f6e9e915ec9",
   "metadata": {},
   "source": [
    "Create a trainer - an object in which we set training parameters such as the number of echoes, graphics card usage, etc."
   ]
  },
  {
   "cell_type": "code",
   "id": "9f8529c6ccb8aaec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T17:21:08.247066Z",
     "start_time": "2024-07-31T17:21:08.220690Z"
    }
   },
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=100,\n",
    "    accelerator=\"gpu\",\n",
    "    log_every_n_steps=10,\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "id": "ce388480fb24f6f2",
   "metadata": {},
   "source": [
    "We start the training with the `fit` method to which we provide the model and datamodule"
   ]
  },
  {
   "cell_type": "code",
   "id": "335d1f72a98c7d44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T17:21:41.387553Z",
     "start_time": "2024-07-31T17:21:14.329711Z"
    }
   },
   "source": [
    "trainer.fit(model, data_module)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kubus\\my_projects\\pytorch_tutor\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "Missing logger folder: C:\\Users\\Kubus\\my_projects\\pytorch_tutor\\lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type             | Params | Mode \n",
      "-----------------------------------------------------------\n",
      "0 | loss_function | CrossEntropyLoss | 0      | train\n",
      "1 | fc1           | Linear           | 6.5 K  | train\n",
      "2 | fc2           | Linear           | 1.0 K  | train\n",
      "-----------------------------------------------------------\n",
      "7.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.5 K     Total params\n",
      "0.030     Total estimated model params size (MB)\n",
      "C:\\Users\\Kubus\\my_projects\\pytorch_tutor\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d5a84ebb7d3b49c5adb5a9a13db6e933"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7988d782131fdc27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T13:27:16.391178Z",
     "start_time": "2024-07-27T13:26:57.538455Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorboard\n",
      "  Downloading tensorboard-2.17.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting absl-py>=0.4 (from tensorboard)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard)\n",
      "  Downloading grpcio-1.65.1-cp311-cp311-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard)\n",
      "  Downloading Markdown-3.6-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from tensorboard) (1.26.3)\n",
      "Collecting protobuf!=4.24.0,<5.0.0,>=3.19.6 (from tensorboard)\n",
      "  Downloading protobuf-4.25.4-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from tensorboard) (65.5.0)\n",
      "Requirement already satisfied: six>1.9 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from tensorboard) (1.16.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard)\n",
      "  Downloading werkzeug-3.0.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
      "Downloading tensorboard-2.17.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/5.5 MB 660.6 kB/s eta 0:00:09\n",
      "    --------------------------------------- 0.1/5.5 MB 787.7 kB/s eta 0:00:07\n",
      "    --------------------------------------- 0.1/5.5 MB 983.0 kB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.2/5.5 MB 919.0 kB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.2/5.5 MB 919.0 kB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.2/5.5 MB 656.9 kB/s eta 0:00:09\n",
      "   - -------------------------------------- 0.3/5.5 MB 787.7 kB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.3/5.5 MB 842.9 kB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.3/5.5 MB 787.7 kB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.3/5.5 MB 787.7 kB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.3/5.5 MB 787.7 kB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.3/5.5 MB 787.7 kB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.3/5.5 MB 583.1 kB/s eta 0:00:09\n",
      "   --- ------------------------------------ 0.4/5.5 MB 671.7 kB/s eta 0:00:08\n",
      "   --- ------------------------------------ 0.5/5.5 MB 777.1 kB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 0.6/5.5 MB 783.3 kB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 0.6/5.5 MB 789.8 kB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 0.7/5.5 MB 794.5 kB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 0.7/5.5 MB 846.4 kB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 0.8/5.5 MB 859.0 kB/s eta 0:00:06\n",
      "   ------ --------------------------------- 0.9/5.5 MB 902.6 kB/s eta 0:00:06\n",
      "   ------ --------------------------------- 0.9/5.5 MB 931.8 kB/s eta 0:00:05\n",
      "   ------- -------------------------------- 1.0/5.5 MB 948.7 kB/s eta 0:00:05\n",
      "   ------- -------------------------------- 1.1/5.5 MB 982.8 kB/s eta 0:00:05\n",
      "   -------- ------------------------------- 1.1/5.5 MB 997.1 kB/s eta 0:00:05\n",
      "   -------- ------------------------------- 1.2/5.5 MB 1.0 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 1.3/5.5 MB 1.0 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 1.4/5.5 MB 1.1 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 1.4/5.5 MB 1.1 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 1.5/5.5 MB 1.1 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 1.6/5.5 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 1.7/5.5 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 1.7/5.5 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 1.8/5.5 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 1.9/5.5 MB 1.2 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 2.0/5.5 MB 1.2 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 2.0/5.5 MB 1.2 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 2.1/5.5 MB 1.2 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 2.2/5.5 MB 1.2 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 2.2/5.5 MB 1.2 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 2.3/5.5 MB 1.2 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 2.4/5.5 MB 1.2 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 2.4/5.5 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 2.5/5.5 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 2.6/5.5 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 2.6/5.5 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 2.7/5.5 MB 1.2 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 2.8/5.5 MB 1.3 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 2.8/5.5 MB 1.3 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 2.9/5.5 MB 1.3 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 3.0/5.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 3.1/5.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 3.1/5.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 3.2/5.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 3.3/5.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 3.3/5.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 3.4/5.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 3.5/5.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 3.5/5.5 MB 1.3 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 3.6/5.5 MB 1.3 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 3.7/5.5 MB 1.3 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 3.7/5.5 MB 1.3 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 3.8/5.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 3.9/5.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 4.0/5.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 4.1/5.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 4.1/5.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 4.2/5.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 4.3/5.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 4.4/5.5 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 4.4/5.5 MB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 4.4/5.5 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 4.5/5.5 MB 1.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 4.6/5.5 MB 1.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 4.7/5.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 4.7/5.5 MB 1.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 4.8/5.5 MB 1.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 4.9/5.5 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.0/5.5 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.0/5.5 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 5.1/5.5 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 5.2/5.5 MB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.3/5.5 MB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.3/5.5 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.4/5.5 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.5/5.5 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 1.4 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "   ---------------------------------------- 0.0/133.7 kB ? eta -:--:--\n",
      "   ------------------ --------------------- 61.4/133.7 kB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 133.7/133.7 kB 2.0 MB/s eta 0:00:00\n",
      "Downloading grpcio-1.65.1-cp311-cp311-win_amd64.whl (4.1 MB)\n",
      "   ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/4.1 MB 991.0 kB/s eta 0:00:05\n",
      "    --------------------------------------- 0.1/4.1 MB 1.3 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.2/4.1 MB 1.6 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.2/4.1 MB 1.5 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.3/4.1 MB 1.4 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.4/4.1 MB 1.6 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 0.5/4.1 MB 1.5 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 0.5/4.1 MB 1.6 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 0.6/4.1 MB 1.6 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 0.7/4.1 MB 1.6 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 0.8/4.1 MB 1.6 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 0.8/4.1 MB 1.5 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 0.9/4.1 MB 1.5 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 0.9/4.1 MB 1.5 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 1.0/4.1 MB 1.5 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 1.0/4.1 MB 1.4 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 1.1/4.1 MB 1.4 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 1.2/4.1 MB 1.4 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 1.2/4.1 MB 1.4 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 1.2/4.1 MB 1.3 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 1.3/4.1 MB 1.3 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 1.4/4.1 MB 1.3 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 1.4/4.1 MB 1.4 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 1.5/4.1 MB 1.4 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 1.6/4.1 MB 1.4 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 1.6/4.1 MB 1.4 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 1.7/4.1 MB 1.4 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 1.8/4.1 MB 1.4 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 1.8/4.1 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 1.9/4.1 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 2.0/4.1 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 2.1/4.1 MB 1.4 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 2.1/4.1 MB 1.4 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 2.2/4.1 MB 1.4 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 2.3/4.1 MB 1.4 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 2.3/4.1 MB 1.4 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 2.4/4.1 MB 1.4 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 2.4/4.1 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 2.5/4.1 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 2.6/4.1 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 2.7/4.1 MB 1.4 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 2.7/4.1 MB 1.4 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 2.8/4.1 MB 1.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 2.9/4.1 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 3.0/4.1 MB 1.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 3.1/4.1 MB 1.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 3.1/4.1 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 3.2/4.1 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 3.3/4.1 MB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 3.3/4.1 MB 1.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 3.4/4.1 MB 1.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 3.5/4.1 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 3.6/4.1 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 3.6/4.1 MB 1.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 3.7/4.1 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 3.8/4.1 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 3.8/4.1 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 3.8/4.1 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 3.9/4.1 MB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 4.0/4.1 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.1/4.1 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.1/4.1 MB 1.5 MB/s eta 0:00:00\n",
      "Downloading Markdown-3.6-py3-none-any.whl (105 kB)\n",
      "   ---------------------------------------- 0.0/105.4 kB ? eta -:--:--\n",
      "   --------------------------- ------------ 71.7/105.4 kB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 105.4/105.4 kB 1.5 MB/s eta 0:00:00\n",
      "Downloading protobuf-4.25.4-cp310-abi3-win_amd64.whl (413 kB)\n",
      "   ---------------------------------------- 0.0/413.4 kB ? eta -:--:--\n",
      "   ------ --------------------------------- 71.7/413.4 kB 2.0 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 143.4/413.4 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 235.5/413.4 kB 1.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 317.4/413.4 kB 1.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 399.4/413.4 kB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 413.4/413.4 kB 1.6 MB/s eta 0:00:00\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading werkzeug-3.0.3-py3-none-any.whl (227 kB)\n",
      "   ---------------------------------------- 0.0/227.3 kB ? eta -:--:--\n",
      "   ---------- ----------------------------- 61.4/227.3 kB 1.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 143.4/227.3 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 227.3/227.3 kB 1.7 MB/s eta 0:00:00\n",
      "Installing collected packages: werkzeug, tensorboard-data-server, protobuf, markdown, grpcio, absl-py, tensorboard\n",
      "Successfully installed absl-py-2.1.0 grpcio-1.65.1 markdown-3.6 protobuf-4.25.4 tensorboard-2.17.0 tensorboard-data-server-0.7.2 werkzeug-3.0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "id": "8f0095630efc8c6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T17:23:42.709982Z",
     "start_time": "2024-07-31T17:23:42.699277Z"
    }
   },
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=./lightning_logs/"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 20496), started 22:21:10 ago. (Use '!kill 20496' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-2d5155e34e422e07\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-2d5155e34e422e07\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "id": "af6b780661e27ac8",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c4a097c0c47071f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T13:28:12.062198Z",
     "start_time": "2024-07-27T13:28:12.054941Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer.save_checkpoint('model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ed0ec0b4790792",
   "metadata": {},
   "source": [
    "## Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7c98677eb4233612",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T13:46:34.571037Z",
     "start_time": "2024-07-27T13:46:34.534239Z"
    }
   },
   "outputs": [],
   "source": [
    "new_model = DigitsModel.load_from_checkpoint('model.ckpt', input_size = 64, num_classes = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6782a27b06defcc0",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2dc2838629ba9de3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T13:47:07.564892Z",
     "start_time": "2024-07-27T13:47:05.417312Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchmetrics in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (1.4.0.post0)\n",
      "Requirement already satisfied: numpy>1.20.0 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from torchmetrics) (1.26.3)\n",
      "Requirement already satisfied: packaging>17.1 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from torchmetrics) (24.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from torchmetrics) (2.3.1+cu118)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from torchmetrics) (0.11.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (65.5.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (3.13.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (2024.2.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.10.0->torchmetrics) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.10.0->torchmetrics) (2021.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "id": "1d1a1600e7675479",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T17:23:51.903777Z",
     "start_time": "2024-07-31T17:23:51.900195Z"
    }
   },
   "source": [
    "import torchmetrics"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "id": "31c057070ff4fc04",
   "metadata": {},
   "source": [
    "We create metrics in the `__init__` function - it is important that training and validation metrics are a separate object\n",
    "\n",
    "Metrics are counted in the `training_step` and `validation_step` functions"
   ]
  },
  {
   "cell_type": "code",
   "id": "8ee6ac1bd8bca96a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T17:23:52.762065Z",
     "start_time": "2024-07-31T17:23:52.754891Z"
    }
   },
   "source": [
    "class DigitsModel(pl.LightningModule):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.loss_function = nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size, 100)\n",
    "        self.fc2 = nn.Linear(100, num_classes)\n",
    "        \n",
    "        self.train_accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes) # test metrics\n",
    "        self.val_accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes) # validation metrics\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        if not self.training:\n",
    "            out = F.softmax(out, dim=1)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters())\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        \n",
    "        outputs = self.forward(inputs.float())\n",
    "        loss = self.loss_function(outputs, labels.long())\n",
    "        \n",
    "        self.log('train_loss', loss)\n",
    "        \n",
    "        outputs = F.softmax(outputs, dim=1)\n",
    "        \n",
    "        self.train_accuracy(outputs, labels)\n",
    "        self.log('train_accuracy', self.train_accuracy, on_epoch=True, on_step=False) # displays the accuracy on the test set every epoch\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        \n",
    "        outputs = self.forward(inputs.float())\n",
    "        loss = self.loss_function(outputs, labels)\n",
    "        \n",
    "        self.log('val_loss', loss)\n",
    "        outputs = F.softmax(outputs, dim=1)\n",
    "        self.val_accuracy(outputs, labels)\n",
    "        self.log('val_accuracy', self.val_accuracy, on_epoch=True, on_step=False)\n",
    "        \n",
    "        return loss\n"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "id": "483d1b5671467541",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T17:23:53.597056Z",
     "start_time": "2024-07-31T17:23:53.591461Z"
    }
   },
   "source": [
    "model_1 = DigitsModel(64, 10)"
   ],
   "outputs": [],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "id": "8e9d0e9aa782b5d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T17:23:54.400958Z",
     "start_time": "2024-07-31T17:23:54.379208Z"
    }
   },
   "source": [
    "trainer = pl.Trainer(max_epochs=100, accelerator=\"gpu\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "id": "86c0c90dc0fc39b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T17:24:24.324733Z",
     "start_time": "2024-07-31T17:23:55.434346Z"
    }
   },
   "source": [
    "trainer.fit(model_1, data_module)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kubus\\my_projects\\pytorch_tutor\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type               | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | loss_function  | CrossEntropyLoss   | 0      | train\n",
      "1 | fc1            | Linear             | 6.5 K  | train\n",
      "2 | fc2            | Linear             | 1.0 K  | train\n",
      "3 | train_accuracy | MulticlassAccuracy | 0      | train\n",
      "4 | val_accuracy   | MulticlassAccuracy | 0      | train\n",
      "--------------------------------------------------------------\n",
      "7.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.5 K     Total params\n",
      "0.030     Total estimated model params size (MB)\n",
      "C:\\Users\\Kubus\\my_projects\\pytorch_tutor\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "C:\\Users\\Kubus\\my_projects\\pytorch_tutor\\.venv\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:298: The number of training batches (45) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f829d11b7ebd40c4b3f9c37b87d95886"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "id": "c8c2c21b03ec21ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T17:24:33.749840Z",
     "start_time": "2024-07-31T17:24:33.740153Z"
    }
   },
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=./lightning_logs/\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 20496), started 22:22:01 ago. (Use '!kill 20496' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-3e059da27bcc598b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-3e059da27bcc598b\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "id": "a8ce26e022df7998",
   "metadata": {},
   "source": [
    "## Additional metrics"
   ]
  },
  {
   "cell_type": "code",
   "id": "32a389206cdca9de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T17:24:40.686953Z",
     "start_time": "2024-07-31T17:24:40.678267Z"
    }
   },
   "source": [
    "class DigitsModel(pl.LightningModule):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.loss_function = nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size, 100)\n",
    "        self.fc2 = nn.Linear(100, num_classes)\n",
    "        \n",
    "        self.train_accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.val_accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        \n",
    "        self.train_macro_f1 = torchmetrics.F1Score(num_classes=num_classes, average='macro', task=\"multiclass\")\n",
    "        self.val_macro_f1 = torchmetrics.F1Score(num_classes=num_classes, average='macro', task=\"multiclass\")\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        if not self.training:\n",
    "            out = F.softmax(out, dim=1)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters())\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self.forward(inputs.float())\n",
    "        loss = self.loss_function(outputs, labels.long())\n",
    "        self.log('train_loss', loss)\n",
    "        \n",
    "        self.train_accuracy(outputs, labels)\n",
    "        self.log('train_accuracy', self.train_accuracy, on_epoch=True, on_step=False)\n",
    "        \n",
    "        self.train_macro_f1(outputs, labels)\n",
    "        self.log(\"train_macro_f1\", self.train_macro_f1, on_epoch=True, on_step=False)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        \n",
    "        outputs = self.forward(inputs.float())\n",
    "        loss = self.loss_function(outputs, labels.long())\n",
    "        self.log('val_loss', loss)\n",
    "        \n",
    "        self.val_accuracy(outputs, labels)\n",
    "        self.log('val_accuracy', self.val_accuracy, on_epoch=True, on_step=False)\n",
    "        \n",
    "        self.val_macro_f1(outputs, labels)\n",
    "        self.log(\"val_macro_f1\", self.val_macro_f1, on_epoch=True, on_step=False)\n",
    "        \n",
    "        return loss\n"
   ],
   "outputs": [],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "id": "26508c4919e604b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T17:24:42.489784Z",
     "start_time": "2024-07-31T17:24:42.484136Z"
    }
   },
   "source": [
    "model = DigitsModel(64, 10)"
   ],
   "outputs": [],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "id": "ba3dbd8c40fc183e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T17:24:42.926188Z",
     "start_time": "2024-07-31T17:24:42.906218Z"
    }
   },
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=100,\n",
    "    accelerator=\"gpu\",\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "id": "7c531b37c915e011",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T17:25:22.037152Z",
     "start_time": "2024-07-31T17:24:43.368470Z"
    }
   },
   "source": [
    "trainer.fit(model, data_module)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kubus\\my_projects\\pytorch_tutor\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type               | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | loss_function  | CrossEntropyLoss   | 0      | train\n",
      "1 | fc1            | Linear             | 6.5 K  | train\n",
      "2 | fc2            | Linear             | 1.0 K  | train\n",
      "3 | train_accuracy | MulticlassAccuracy | 0      | train\n",
      "4 | val_accuracy   | MulticlassAccuracy | 0      | train\n",
      "5 | train_macro_f1 | MulticlassF1Score  | 0      | train\n",
      "6 | val_macro_f1   | MulticlassF1Score  | 0      | train\n",
      "--------------------------------------------------------------\n",
      "7.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.5 K     Total params\n",
      "0.030     Total estimated model params size (MB)\n",
      "C:\\Users\\Kubus\\my_projects\\pytorch_tutor\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "C:\\Users\\Kubus\\my_projects\\pytorch_tutor\\.venv\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:298: The number of training batches (45) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b8a21fcd415242eca4cd12cb7052a2ec"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "id": "53c205f86ba53e24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T17:25:26.975927Z",
     "start_time": "2024-07-31T17:25:26.964706Z"
    }
   },
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=./lightning_logs/"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 20496), started 22:22:54 ago. (Use '!kill 20496' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-289932196a927b1e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-289932196a927b1e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 43
  },
  {
   "cell_type": "markdown",
   "id": "b572d4cae5c5dcb7",
   "metadata": {},
   "source": "# Exercises"
  },
  {
   "cell_type": "markdown",
   "id": "b3ce9c9ee4a64d61",
   "metadata": {},
   "source": [
    "The aim of the exercise is to create a model to detect whether a patient has diabetes based on laboratory results\n",
    "\n",
    "https://www.kaggle.com/datasets/akshaydattatraykhare/diabetes-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab65b44e9ce6ade",
   "metadata": {},
   "source": [
    "Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "87a965c99667d65f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T19:07:28.774520Z",
     "start_time": "2024-07-27T19:07:26.599950Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from requests) (2024.7.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "395b8f8cbcca04b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T19:07:36.575798Z",
     "start_time": "2024-07-27T19:07:36.556602Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wget -O diabetes_data.csv https://pastebin.com/raw/qdrUE0E0 # does not work on windows"
   ]
  },
  {
   "cell_type": "code",
   "id": "54ddddb9df293db0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T21:00:51.743292Z",
     "start_time": "2024-08-03T21:00:50.066853Z"
    }
   },
   "source": [
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "8520278093db8807",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T21:00:51.760805Z",
     "start_time": "2024-08-03T21:00:51.744326Z"
    }
   },
   "source": [
    "data = pd.read_csv('diabetes_data.csv')"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "79fa616707e5ca05",
   "metadata": {},
   "source": [
    "Visualization of the collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59484c204edde06d",
   "metadata": {},
   "source": [
    "We will try to predict the value of the `Outcome` column based on the values of laboratory results and patient characteristics - other columns"
   ]
  },
  {
   "cell_type": "code",
   "id": "403b3bc3c6900d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T21:00:51.778777Z",
     "start_time": "2024-08-03T21:00:51.761831Z"
    }
   },
   "source": [
    "data"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows  9 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "59f37eda2dca3fd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T21:00:51.785882Z",
     "start_time": "2024-08-03T21:00:51.780314Z"
    }
   },
   "source": [
    "feature_columns = data.drop(columns=['Outcome'])"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "83c4de137938400b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T21:00:52.850374Z",
     "start_time": "2024-08-03T21:00:52.839041Z"
    }
   },
   "source": [
    "feature_columns"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  \n",
       "0                       0.627   50  \n",
       "1                       0.351   31  \n",
       "2                       0.672   32  \n",
       "3                       0.167   21  \n",
       "4                       2.288   33  \n",
       "..                        ...  ...  \n",
       "763                     0.171   63  \n",
       "764                     0.340   27  \n",
       "765                     0.245   30  \n",
       "766                     0.349   47  \n",
       "767                     0.315   23  \n",
       "\n",
       "[768 rows x 8 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows  8 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "861ce82c924efee6",
   "metadata": {},
   "source": [
    "We need to standardize the data for each column - subtract the mean and divide by the standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "id": "12d5cef3d3febba4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T21:00:54.014513Z",
     "start_time": "2024-08-03T21:00:54.000184Z"
    }
   },
   "source": [
    "def standardize(x):\n",
    "    x_std = x.copy(deep=True)\n",
    "    for c in feature_columns:\n",
    "        x_std[c] = (x_std[c] - x_std[c].mean()) / x_std[c].std()\n",
    "    \n",
    "    return x_std\n",
    "\n",
    "data = standardize(data)\n",
    "data.head()\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Pregnancies   Glucose  BloodPressure  SkinThickness   Insulin       BMI  \\\n",
       "0     0.639530  0.847771       0.149543       0.906679 -0.692439  0.203880   \n",
       "1    -0.844335 -1.122665      -0.160441       0.530556 -0.692439 -0.683976   \n",
       "2     1.233077  1.942458      -0.263769      -1.287373 -0.692439 -1.102537   \n",
       "3    -0.844335 -0.997558      -0.160441       0.154433  0.123221 -0.493721   \n",
       "4    -1.141108  0.503727      -1.503707       0.906679  0.765337  1.408828   \n",
       "\n",
       "   DiabetesPedigreeFunction       Age  Outcome  \n",
       "0                  0.468187  1.425067        1  \n",
       "1                 -0.364823 -0.190548        0  \n",
       "2                  0.604004 -0.105515        1  \n",
       "3                 -0.920163 -1.040871        0  \n",
       "4                  5.481337 -0.020483        1  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.639530</td>\n",
       "      <td>0.847771</td>\n",
       "      <td>0.149543</td>\n",
       "      <td>0.906679</td>\n",
       "      <td>-0.692439</td>\n",
       "      <td>0.203880</td>\n",
       "      <td>0.468187</td>\n",
       "      <td>1.425067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.844335</td>\n",
       "      <td>-1.122665</td>\n",
       "      <td>-0.160441</td>\n",
       "      <td>0.530556</td>\n",
       "      <td>-0.692439</td>\n",
       "      <td>-0.683976</td>\n",
       "      <td>-0.364823</td>\n",
       "      <td>-0.190548</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.233077</td>\n",
       "      <td>1.942458</td>\n",
       "      <td>-0.263769</td>\n",
       "      <td>-1.287373</td>\n",
       "      <td>-0.692439</td>\n",
       "      <td>-1.102537</td>\n",
       "      <td>0.604004</td>\n",
       "      <td>-0.105515</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.844335</td>\n",
       "      <td>-0.997558</td>\n",
       "      <td>-0.160441</td>\n",
       "      <td>0.154433</td>\n",
       "      <td>0.123221</td>\n",
       "      <td>-0.493721</td>\n",
       "      <td>-0.920163</td>\n",
       "      <td>-1.040871</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.141108</td>\n",
       "      <td>0.503727</td>\n",
       "      <td>-1.503707</td>\n",
       "      <td>0.906679</td>\n",
       "      <td>0.765337</td>\n",
       "      <td>1.408828</td>\n",
       "      <td>5.481337</td>\n",
       "      <td>-0.020483</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "b9b06307e6c1dfb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T21:00:54.711886Z",
     "start_time": "2024-08-03T21:00:54.706793Z"
    }
   },
   "source": [
    "data.to_numpy()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.63953049,  0.84777132,  0.1495433 , ...,  0.46818687,\n",
       "         1.42506672,  1.        ],\n",
       "       [-0.84433482, -1.12266474, -0.16044119, ..., -0.36482303,\n",
       "        -0.19054773,  0.        ],\n",
       "       [ 1.23307662,  1.94245802, -0.26376935, ...,  0.6040037 ,\n",
       "        -0.10551539,  1.        ],\n",
       "       ...,\n",
       "       [ 0.34275743,  0.00329872,  0.1495433 , ..., -0.68474712,\n",
       "        -0.27558007,  0.        ],\n",
       "       [-0.84433482,  0.15968254, -0.47042568, ..., -0.37085933,\n",
       "         1.1699697 ,  1.        ],\n",
       "       [-0.84433482, -0.87245064,  0.04621514, ..., -0.4734765 ,\n",
       "        -0.87080644,  0.        ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "795f757e1c45e26a",
   "metadata": {},
   "source": [
    "## 1. Creates dataset and datamodule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240b01254a61b1bc",
   "metadata": {},
   "source": [
    "### a) Divide the data into input (x) and output (y):\n",
    "\n",
    "y - outcome column\n",
    "x - remaining columns\n",
    "\n",
    "Convert x and y to numpy"
   ]
  },
  {
   "cell_type": "code",
   "id": "406a9a86c809385a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T21:00:57.118275Z",
     "start_time": "2024-08-03T21:00:57.114153Z"
    }
   },
   "source": [
    "y = data[\"Outcome\"]\n",
    "x = data.drop(\"Outcome\", axis=1)"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "1c3f8d0b8ad12399",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T21:00:58.070089Z",
     "start_time": "2024-08-03T21:00:58.063321Z"
    }
   },
   "source": [
    "y"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      0\n",
       "2      1\n",
       "3      0\n",
       "4      1\n",
       "      ..\n",
       "763    0\n",
       "764    0\n",
       "765    0\n",
       "766    1\n",
       "767    0\n",
       "Name: Outcome, Length: 768, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "6a5506dcc89e6dc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T21:00:59.125831Z",
     "start_time": "2024-08-03T21:00:59.119185Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array(x)\n",
    "y = y.apply(lambda x: [float(x)]).tolist()\n",
    "y = np.array(y)\n",
    "\n",
    "x"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.63953049,  0.84777132,  0.1495433 , ...,  0.20387991,\n",
       "         0.46818687,  1.42506672],\n",
       "       [-0.84433482, -1.12266474, -0.16044119, ..., -0.68397621,\n",
       "        -0.36482303, -0.19054773],\n",
       "       [ 1.23307662,  1.94245802, -0.26376935, ..., -1.10253696,\n",
       "         0.6040037 , -0.10551539],\n",
       "       ...,\n",
       "       [ 0.34275743,  0.00329872,  0.1495433 , ..., -0.73471085,\n",
       "        -0.68474712, -0.27558007],\n",
       "       [-0.84433482,  0.15968254, -0.47042568, ..., -0.24004815,\n",
       "        -0.37085933,  1.1699697 ],\n",
       "       [-0.84433482, -0.87245064,  0.04621514, ..., -0.20199718,\n",
       "        -0.4734765 , -0.87080644]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "4571c113b761216",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T21:01:00.464039Z",
     "start_time": "2024-08-03T21:01:00.453826Z"
    }
   },
   "source": [
    "y"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "b830076fdbfc64a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T21:01:07.098148Z",
     "start_time": "2024-08-03T21:01:03.322102Z"
    }
   },
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "877167d742559600",
   "metadata": {},
   "source": [
    "### b) Create dataset class"
   ]
  },
  {
   "cell_type": "code",
   "id": "3f29ccf92341333b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T21:01:07.103749Z",
     "start_time": "2024-08-03T21:01:07.099167Z"
    }
   },
   "source": [
    "class DiabetesDataset(Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx]\n",
    "        y = self.targets[idx]\n",
    "        \n",
    "        return x, y\n"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "35a998abbd7ec6dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T21:01:07.108884Z",
     "start_time": "2024-08-03T21:01:07.104774Z"
    }
   },
   "source": [
    "dataset = DiabetesDataset(x, y)"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "ca5fa6129ba6f8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T21:01:07.916517Z",
     "start_time": "2024-08-03T21:01:07.912912Z"
    }
   },
   "source": [
    "sample_data, sample_target = dataset[0]"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "1975abc323634b80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T21:01:08.829393Z",
     "start_time": "2024-08-03T21:01:08.823786Z"
    }
   },
   "source": [
    "sample_data"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.63953049,  0.84777132,  0.1495433 ,  0.90667906, -0.69243932,\n",
       "        0.20387991,  0.46818687,  1.42506672])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "508e3449a5804c5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T21:01:09.698524Z",
     "start_time": "2024-08-03T21:01:09.692834Z"
    }
   },
   "source": [
    "sample_target"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "id": "6bb4b54f19bc8617",
   "metadata": {},
   "source": [
    "### c) Create Datamodule class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fa7f42f14d3551",
   "metadata": {},
   "source": [
    "The class should:\n",
    "* In the `prepare_data` method:\n",
    "    * load data from disk\n",
    "* In the `setup` method:\n",
    "    * standardize data\n",
    "    * divide into x and y\n",
    "    * divide into x and y into training and testing\n",
    "    * create training and test datasets from the DiabetesDataset class\n",
    "* In the `train_dataloader` method\n",
    "    * rip the dataloader for the training set\n",
    "* In the `val_dataloader` method\n",
    "    * return dataloader for validation set"
   ]
  },
  {
   "cell_type": "code",
   "id": "11c77d333d947f20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T21:01:18.165298Z",
     "start_time": "2024-08-03T21:01:11.842292Z"
    }
   },
   "source": [
    "import pytorch_lightning as pl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "fb10f4f002b7fc02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T21:01:18.174506Z",
     "start_time": "2024-08-03T21:01:18.166838Z"
    }
   },
   "source": [
    "class DiabetesDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size = 32):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def prepare_data(self) -> None:\n",
    "        self.data = pd.read_csv('diabetes_data.csv')\n",
    "        \n",
    "    def _standardize(self, x):\n",
    "        x_std = x.copy(deep=True)\n",
    "        feature_columns = data.drop(columns=['Outcome'])\n",
    "    \n",
    "        for c in feature_columns:\n",
    "            x_std[c] = (x_std[c] - x_std[c].mean()) / x_std[c].std()\n",
    "        \n",
    "        return x_std\n",
    "    \n",
    "    def setup(self, stage = None):\n",
    "        data = self._standardize(self.data)\n",
    "        y = data[\"Outcome\"]\n",
    "        x = data.drop(\"Outcome\", axis=1)\n",
    "        \n",
    "        x = np.array(x)\n",
    "        y = y.apply(lambda x: [float(x)]).tolist()\n",
    "        y = np.array(y)\n",
    "        \n",
    "        train_X, test_X, train_y, test_y = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        self.train_dataset = DiabetesDataset(train_X, train_y)\n",
    "        self.test_dataset = DiabetesDataset(test_X, test_y)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False)\n"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "dc5fc869ce3739f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T21:01:18.180118Z",
     "start_time": "2024-08-03T21:01:18.175024Z"
    }
   },
   "source": [
    "data_module = DiabetesDataModule()"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "2f9da5e020b83e63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T21:01:18.189793Z",
     "start_time": "2024-08-03T21:01:18.181638Z"
    }
   },
   "source": [
    "data_module.prepare_data()"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "68229682b21eaa1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T21:01:18.200529Z",
     "start_time": "2024-08-03T21:01:18.190812Z"
    }
   },
   "source": [
    "data_module.setup()"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "id": "67cb35fd9dc557e0",
   "metadata": {},
   "source": [
    "Test - visualization of one batch"
   ]
  },
  {
   "cell_type": "code",
   "id": "ce6c77e8944b47cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T21:01:18.215517Z",
     "start_time": "2024-08-03T21:01:18.202167Z"
    }
   },
   "source": [
    "next(iter(data_module.train_dataloader()))[0].shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 8])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "cc92c7edc7a54722",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T21:01:18.222109Z",
     "start_time": "2024-08-03T21:01:18.216672Z"
    }
   },
   "source": [
    "next(iter(data_module.train_dataloader()))[1].shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "id": "19ecbe3272938859",
   "metadata": {},
   "source": [
    "## Create and train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5d86c24f3a4b2",
   "metadata": {},
   "source": [
    "Implement any neural network to solve the classification problem\n",
    "\n",
    "As error functions use binary cross entropp `BCELoss` since we are dealing with binary classification\n",
    "\n",
    "The sigmoid function should be used as the last activation function in the network\n",
    "\n",
    "Add a precision metric for the training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "id": "f496943e60a0c36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T21:01:21.462218Z",
     "start_time": "2024-08-03T21:01:21.459155Z"
    }
   },
   "source": [
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torchmetrics\n",
    "import torch"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "id": "d5b8c97ce96cc6b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T21:04:52.456870Z",
     "start_time": "2024-08-03T21:04:52.448598Z"
    }
   },
   "source": [
    "class DiabetesNet(pl.LightningModule):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.loss_function = nn.BCELoss()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size, num_classes)\n",
    "        self.fc2 = nn.Linear(num_classes, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        self.train_accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.val_accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        \n",
    "        self.train_pred = torchmetrics.Precision(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.val_pred = torchmetrics.Precision(task=\"multiclass\", num_classes=num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters())\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        inputs = inputs.float()\n",
    "        labels = labels.float()\n",
    "        outputs = self.forward(inputs)\n",
    "        \n",
    "        loss = self.loss_function(outputs, labels)\n",
    "        self.log('train_loss', loss)\n",
    "        \n",
    "        outputs = self.sigmoid(outputs)\n",
    "        \n",
    "        self.train_accuracy(outputs, labels)        \n",
    "        train_pred = self.train_pred(outputs, labels)\n",
    "        self.log(\"train_pred\", train_pred, on_epoch=True, on_step=False)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        # log epoch metric\n",
    "        self.log('train_accuracy', self.train_accuracy, on_epoch=True, on_step=False)\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        inputs = inputs.float()\n",
    "        labels = labels.float()\n",
    "        outputs = self.forward(inputs)\n",
    "        loss = self.loss_function(outputs, labels)\n",
    "        self.log('val_loss', loss)\n",
    "        \n",
    "        outputs = self.sigmoid(outputs)\n",
    "        \n",
    "        self.val_accuracy(outputs, labels)\n",
    "        self.log('val_accuracy', self.val_accuracy, on_epoch=True, on_step=False)\n",
    "        \n",
    "        val_pred = self.val_pred(outputs, labels)\n",
    "        self.log(\"val_pred\", val_pred, on_epoch=True, on_step=False)\n",
    "        \n",
    "        return loss\n"
   ],
   "outputs": [],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "id": "a86f2bcd76579832",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T21:04:53.100646Z",
     "start_time": "2024-08-03T21:04:53.093961Z"
    }
   },
   "source": [
    "model = DiabetesNet(8, 32)"
   ],
   "outputs": [],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "id": "fecd08b51b36830",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T21:04:53.472098Z",
     "start_time": "2024-08-03T21:04:53.453658Z"
    }
   },
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=100,\n",
    "    accelerator=\"gpu\",\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "id": "a476aa7339504a75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T21:04:54.090759Z",
     "start_time": "2024-08-03T21:04:53.980071Z"
    }
   },
   "source": [
    "trainer.fit(model, data_module)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "File \u001B[1;32m~\\my_projects\\pytorch_tutor\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:44\u001B[0m, in \u001B[0;36m_call_and_handle_interrupt\u001B[1;34m(trainer, trainer_fn, *args, **kwargs)\u001B[0m\n\u001B[0;32m     43\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher\u001B[38;5;241m.\u001B[39mlaunch(trainer_fn, \u001B[38;5;241m*\u001B[39margs, trainer\u001B[38;5;241m=\u001B[39mtrainer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m---> 44\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtrainer_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     46\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _TunerExitException:\n",
      "File \u001B[1;32m~\\my_projects\\pytorch_tutor\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:579\u001B[0m, in \u001B[0;36mTrainer._fit_impl\u001B[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[0;32m    573\u001B[0m ckpt_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_checkpoint_connector\u001B[38;5;241m.\u001B[39m_select_ckpt_path(\n\u001B[0;32m    574\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn,\n\u001B[0;32m    575\u001B[0m     ckpt_path,\n\u001B[0;32m    576\u001B[0m     model_provided\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    577\u001B[0m     model_connected\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    578\u001B[0m )\n\u001B[1;32m--> 579\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mckpt_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    581\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstopped\n",
      "File \u001B[1;32m~\\my_projects\\pytorch_tutor\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:962\u001B[0m, in \u001B[0;36mTrainer._run\u001B[1;34m(self, model, ckpt_path)\u001B[0m\n\u001B[0;32m    961\u001B[0m \u001B[38;5;66;03m# strategy will configure model and move it to the device\u001B[39;00m\n\u001B[1;32m--> 962\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstrategy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msetup\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    964\u001B[0m \u001B[38;5;66;03m# hook\u001B[39;00m\n",
      "File \u001B[1;32m~\\my_projects\\pytorch_tutor\\.venv\\Lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:148\u001B[0m, in \u001B[0;36mStrategy.setup\u001B[1;34m(self, trainer)\u001B[0m\n\u001B[0;32m    147\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccelerator \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 148\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maccelerator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msetup\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    150\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\my_projects\\pytorch_tutor\\.venv\\Lib\\site-packages\\pytorch_lightning\\accelerators\\cuda.py:53\u001B[0m, in \u001B[0;36mCUDAAccelerator.setup\u001B[1;34m(self, trainer)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mset_nvidia_flags(trainer\u001B[38;5;241m.\u001B[39mlocal_rank)\n\u001B[1;32m---> 53\u001B[0m \u001B[43m_clear_cuda_memory\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\my_projects\\pytorch_tutor\\.venv\\Lib\\site-packages\\lightning_fabric\\accelerators\\cuda.py:181\u001B[0m, in \u001B[0;36m_clear_cuda_memory\u001B[1;34m()\u001B[0m\n\u001B[0;32m    180\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_cuda_clearCublasWorkspaces()\n\u001B[1;32m--> 181\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mempty_cache\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\my_projects\\pytorch_tutor\\.venv\\Lib\\site-packages\\torch\\cuda\\memory.py:162\u001B[0m, in \u001B[0;36mempty_cache\u001B[1;34m()\u001B[0m\n\u001B[0;32m    161\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_initialized():\n\u001B[1;32m--> 162\u001B[0m     \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_C\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_cuda_emptyCache\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[38], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata_module\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\my_projects\\pytorch_tutor\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:543\u001B[0m, in \u001B[0;36mTrainer.fit\u001B[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[0;32m    541\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m=\u001B[39m TrainerStatus\u001B[38;5;241m.\u001B[39mRUNNING\n\u001B[0;32m    542\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m--> 543\u001B[0m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_and_handle_interrupt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    544\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_impl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatamodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\n\u001B[0;32m    545\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\my_projects\\pytorch_tutor\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:60\u001B[0m, in \u001B[0;36m_call_and_handle_interrupt\u001B[1;34m(trainer, trainer_fn, *args, **kwargs)\u001B[0m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exception:\n\u001B[0;32m     59\u001B[0m     _interrupt(trainer, exception)\n\u001B[1;32m---> 60\u001B[0m     \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_teardown\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     61\u001B[0m     \u001B[38;5;66;03m# teardown might access the stage so we reset it after\u001B[39;00m\n\u001B[0;32m     62\u001B[0m     trainer\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstage \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\my_projects\\pytorch_tutor\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1009\u001B[0m, in \u001B[0;36mTrainer._teardown\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1006\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_teardown\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1007\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"This is the Trainer's internal teardown, unrelated to the `teardown` hooks in LightningModule and Callback;\u001B[39;00m\n\u001B[0;32m   1008\u001B[0m \u001B[38;5;124;03m    those are handled by :meth:`_call_teardown_hook`.\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1009\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstrategy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mteardown\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1010\u001B[0m     loop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_active_loop\n\u001B[0;32m   1011\u001B[0m     \u001B[38;5;66;03m# loop should never be `None` here but it can because we don't know the trainer stage with `ddp_spawn`\u001B[39;00m\n",
      "File \u001B[1;32m~\\my_projects\\pytorch_tutor\\.venv\\Lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:538\u001B[0m, in \u001B[0;36mStrategy.teardown\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    536\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprecision_plugin\u001B[38;5;241m.\u001B[39mteardown()\n\u001B[0;32m    537\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccelerator \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 538\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maccelerator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mteardown\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    539\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheckpoint_io\u001B[38;5;241m.\u001B[39mteardown()\n",
      "File \u001B[1;32m~\\my_projects\\pytorch_tutor\\.venv\\Lib\\site-packages\\pytorch_lightning\\accelerators\\cuda.py:82\u001B[0m, in \u001B[0;36mCUDAAccelerator.teardown\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     80\u001B[0m \u001B[38;5;129m@override\u001B[39m\n\u001B[0;32m     81\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mteardown\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m---> 82\u001B[0m     \u001B[43m_clear_cuda_memory\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\my_projects\\pytorch_tutor\\.venv\\Lib\\site-packages\\lightning_fabric\\accelerators\\cuda.py:181\u001B[0m, in \u001B[0;36m_clear_cuda_memory\u001B[1;34m()\u001B[0m\n\u001B[0;32m    178\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(torch\u001B[38;5;241m.\u001B[39m_C, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_cuda_clearCublasWorkspaces\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    179\u001B[0m     \u001B[38;5;66;03m# https://github.com/pytorch/pytorch/issues/95668\u001B[39;00m\n\u001B[0;32m    180\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_cuda_clearCublasWorkspaces()\n\u001B[1;32m--> 181\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mempty_cache\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\my_projects\\pytorch_tutor\\.venv\\Lib\\site-packages\\torch\\cuda\\memory.py:162\u001B[0m, in \u001B[0;36mempty_cache\u001B[1;34m()\u001B[0m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Release all unoccupied cached memory currently held by the caching\u001B[39;00m\n\u001B[0;32m    152\u001B[0m \u001B[38;5;124;03mallocator so that those can be used in other GPU application and visible in\u001B[39;00m\n\u001B[0;32m    153\u001B[0m \u001B[38;5;124;03m`nvidia-smi`.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    159\u001B[0m \u001B[38;5;124;03m    more details about GPU memory management.\u001B[39;00m\n\u001B[0;32m    160\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    161\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_initialized():\n\u001B[1;32m--> 162\u001B[0m     \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_C\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_cuda_emptyCache\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "id": "7a619cd08130b934",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T20:41:51.704928Z",
     "start_time": "2024-07-30T20:41:51.693636Z"
    }
   },
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=./lightning_logs/"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 20496), started 1:39:19 ago. (Use '!kill 20496' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-5bcaa3fe0ecbe18f\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-5bcaa3fe0ecbe18f\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 188
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c23ac3c16684e97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
