{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Download data",
   "id": "78180b70b342d7bc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html#sklearn.datasets.load_digits",
   "id": "8798c13fced7ab9a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T19:53:48.799776Z",
     "start_time": "2024-07-25T19:53:30.747801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pytorch_lightning.utilities.types import OptimizerLRScheduler\n",
    "!pip install pytorch-lightning"
   ],
   "id": "61f66f246c67a7ac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-lightning\n",
      "  Downloading pytorch_lightning-2.3.3-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: numpy>=1.17.2 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from pytorch-lightning) (1.26.3)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from pytorch-lightning) (2.3.1+cu118)\n",
      "Collecting tqdm>=4.57.0 (from pytorch-lightning)\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.6 kB ? eta -:--:--\n",
      "     ------- -------------------------------- 10.2/57.6 kB ? eta -:--:--\n",
      "     -------------------------------------- 57.6/57.6 kB 751.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: PyYAML>=5.4 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from pytorch-lightning) (6.0.1)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2024.2.0)\n",
      "Collecting torchmetrics>=0.7.0 (from pytorch-lightning)\n",
      "  Downloading torchmetrics-1.4.0.post0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from pytorch-lightning) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from pytorch-lightning) (4.12.2)\n",
      "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning)\n",
      "  Downloading lightning_utilities-0.11.6-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>=2022.5.0->pytorch-lightning)\n",
      "  Downloading aiohttp-3.9.5-cp311-cp311-win_amd64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (65.5.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from torch>=2.0.0->pytorch-lightning) (3.13.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from torch>=2.0.0->pytorch-lightning) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from torch>=2.0.0->pytorch-lightning) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from torch>=2.0.0->pytorch-lightning) (3.1.4)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from torch>=2.0.0->pytorch-lightning) (2021.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from tqdm>=4.57.0->pytorch-lightning) (0.4.6)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (23.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning)\n",
      "  Downloading frozenlist-1.4.1-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning)\n",
      "  Downloading multidict-6.0.5-cp311-cp311-win_amd64.whl.metadata (4.3 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning)\n",
      "  Downloading yarl-1.9.4-cp311-cp311-win_amd64.whl.metadata (32 kB)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=2.0.0->pytorch-lightning) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=2.0.0->pytorch-lightning) (2021.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from jinja2->torch>=2.0.0->pytorch-lightning) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from sympy->torch>=2.0.0->pytorch-lightning) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.7)\n",
      "Downloading pytorch_lightning-2.3.3-py3-none-any.whl (812 kB)\n",
      "   ---------------------------------------- 0.0/812.3 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 61.4/812.3 kB 3.4 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 71.7/812.3 kB 2.0 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 71.7/812.3 kB 2.0 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 204.8/812.3 kB 1.6 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 245.8/812.3 kB 1.2 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 307.2/812.3 kB 1.2 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 368.6/812.3 kB 1.2 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 368.6/812.3 kB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 532.5/812.3 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 583.7/812.3 kB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 634.9/812.3 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 696.3/812.3 kB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 768.0/812.3 kB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 778.2/812.3 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  798.7/812.3 kB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 812.3/812.3 kB 1.2 MB/s eta 0:00:00\n",
      "Downloading lightning_utilities-0.11.6-py3-none-any.whl (26 kB)\n",
      "Downloading torchmetrics-1.4.0.post0-py3-none-any.whl (868 kB)\n",
      "   ---------------------------------------- 0.0/868.8 kB ? eta -:--:--\n",
      "   - -------------------------------------- 30.7/868.8 kB 1.3 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 92.2/868.8 kB 1.3 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 133.1/868.8 kB 1.1 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 194.6/868.8 kB 1.2 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 245.8/868.8 kB 1.3 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 317.4/868.8 kB 1.2 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 368.6/868.8 kB 1.2 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 399.4/868.8 kB 1.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 471.0/868.8 kB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 491.5/868.8 kB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 563.2/868.8 kB 1.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 604.2/868.8 kB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 655.4/868.8 kB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 686.1/868.8 kB 1.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 737.3/868.8 kB 1.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 768.0/868.8 kB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 819.2/868.8 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 868.8/868.8 kB 1.1 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.3 kB ? eta -:--:--\n",
      "   -------------------- ------------------- 41.0/78.3 kB 991.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 78.3/78.3 kB 1.1 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.9.5-cp311-cp311-win_amd64.whl (370 kB)\n",
      "   ---------------------------------------- 0.0/370.8 kB ? eta -:--:--\n",
      "   ---- ----------------------------------- 41.0/370.8 kB 1.9 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 92.2/370.8 kB 1.1 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 143.4/370.8 kB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 204.8/370.8 kB 1.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 276.5/370.8 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 317.4/370.8 kB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 370.8/370.8 kB 1.2 MB/s eta 0:00:00\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.4.1-cp311-cp311-win_amd64.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.5/50.5 kB 1.3 MB/s eta 0:00:00\n",
      "Downloading multidict-6.0.5-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Downloading yarl-1.9.4-cp311-cp311-win_amd64.whl (76 kB)\n",
      "   ---------------------------------------- 0.0/76.7 kB ? eta -:--:--\n",
      "   ---------------- ----------------------- 30.7/76.7 kB 660.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 76.7/76.7 kB 1.1 MB/s eta 0:00:00\n",
      "Installing collected packages: tqdm, multidict, lightning-utilities, frozenlist, yarl, aiosignal, torchmetrics, aiohttp, pytorch-lightning\n",
      "Successfully installed aiohttp-3.9.5 aiosignal-1.3.1 frozenlist-1.4.1 lightning-utilities-0.11.6 multidict-6.0.5 pytorch-lightning-2.3.3 torchmetrics-1.4.0.post0 tqdm-4.66.4 yarl-1.9.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T13:24:14.925296Z",
     "start_time": "2024-07-27T13:24:14.922222Z"
    }
   },
   "cell_type": "code",
   "source": "from sklearn.datasets import load_digits",
   "id": "a42a59cd4c37c0eb",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T13:24:15.078099Z",
     "start_time": "2024-07-27T13:24:15.058692Z"
    }
   },
   "cell_type": "code",
   "source": "data = load_digits().data",
   "id": "52d3f02100db5438",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T13:24:15.366547Z",
     "start_time": "2024-07-27T13:24:15.362188Z"
    }
   },
   "cell_type": "code",
   "source": "data.shape",
   "id": "fbe626350a6016ee",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T13:24:15.547958Z",
     "start_time": "2024-07-27T13:24:15.543187Z"
    }
   },
   "cell_type": "code",
   "source": "data[0]",
   "id": "453de6fc7ebc9dd5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n",
       "       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n",
       "       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n",
       "        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n",
       "       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T13:24:15.729573Z",
     "start_time": "2024-07-27T13:24:15.708702Z"
    }
   },
   "cell_type": "code",
   "source": "targets = load_digits().target",
   "id": "c0668291874ac612",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T13:24:15.881890Z",
     "start_time": "2024-07-27T13:24:15.877251Z"
    }
   },
   "cell_type": "code",
   "source": "targets.shape",
   "id": "88773ecb6c131185",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T13:24:16.051553Z",
     "start_time": "2024-07-27T13:24:16.045871Z"
    }
   },
   "cell_type": "code",
   "source": "targets[0]",
   "id": "5806d7ae39fa2ed6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Split data into training and testing",
   "id": "72b2bd8cfa3d5480"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "to split data into training and testing use `train_test_split()` function from sklearn.",
   "id": "2d8bed7465e0aced"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Parameters `stratify` will ensure the same distribution of data in the training and testing sets, in our case we want the distribution of classes to be the same in both sets, so we specify `stratify = traget` which will ensure an equal distribution of data with respect to the target variable",
   "id": "4173acae2fc280c3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T13:24:16.705956Z",
     "start_time": "2024-07-27T13:24:16.702371Z"
    }
   },
   "cell_type": "code",
   "source": "from sklearn.model_selection import train_test_split",
   "id": "1516dcc8d3af0169",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T13:24:16.890012Z",
     "start_time": "2024-07-27T13:24:16.884832Z"
    }
   },
   "cell_type": "code",
   "source": "train_X, test_X, train_y, test_y = train_test_split(data, targets, test_size=0.2, stratify=targets)",
   "id": "551c070f304a3857",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T13:24:17.014110Z",
     "start_time": "2024-07-27T13:24:17.010034Z"
    }
   },
   "cell_type": "code",
   "source": "train_X.shape",
   "id": "649848c29d4fff92",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1437, 64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T13:24:17.197925Z",
     "start_time": "2024-07-27T13:24:17.193269Z"
    }
   },
   "cell_type": "code",
   "source": "train_X[0]",
   "id": "b43f982803c1aafd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  5., 12., 16., 15.,  2.,  0.,  0.,  6., 15.,  9., 10.,\n",
       "       15.,  4.,  0.,  0.,  3., 14.,  3.,  1., 14.,  4.,  0.,  0.,  0.,\n",
       "       10., 16., 15., 13.,  1.,  0.,  0.,  0.,  6., 15., 15., 10.,  0.,\n",
       "        0.,  0.,  0., 15.,  3.,  2., 15.,  3.,  0.,  0.,  0., 16.,  8.,\n",
       "        1., 14.,  4.,  0.,  0.,  0.,  4., 15., 16., 11.,  2.,  0.])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T13:24:17.351958Z",
     "start_time": "2024-07-27T13:24:17.347722Z"
    }
   },
   "cell_type": "code",
   "source": "test_X.shape",
   "id": "72689135c6ecfec0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T13:24:17.533360Z",
     "start_time": "2024-07-27T13:24:17.529256Z"
    }
   },
   "cell_type": "code",
   "source": "train_X[1]",
   "id": "2671e0dcd3f6827d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  1., 10., 16.,  8.,  0.,  0.,  0.,  0., 11., 13., 10.,\n",
       "       16.,  0.,  0.,  0.,  0., 12.,  1.,  4., 16.,  1.,  0.,  0.,  0.,\n",
       "        1.,  0., 13.,  7.,  0.,  0.,  0.,  0.,  0.,  9., 12.,  0.,  0.,\n",
       "        0.,  0.,  2., 13., 15.,  1.,  0.,  0.,  0.,  0.,  4., 15., 14.,\n",
       "        7.,  4.,  0.,  0.,  0.,  0.,  1., 11., 14., 15.,  5.,  0.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Datamodule",
   "id": "b8767ed235eb7e47"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Dataset",
   "id": "a5e16b8b39cbb9f2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T13:24:18.470270Z",
     "start_time": "2024-07-27T13:24:18.467716Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset\n",
    "import pytorch_lightning as pl"
   ],
   "id": "1d456e2431b4d605",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T13:24:18.840814Z",
     "start_time": "2024-07-27T13:24:18.836627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DigitsDataset(Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx] / 255\n",
    "        y = self.targets[idx]\n",
    "        \n",
    "        return x, y"
   ],
   "id": "e707c9626324453f",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Datamodule",
   "id": "8f60d4df86350b41"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "https://pytorch-lightning.readthedocs.io/en/stable/data/datamodule.html",
   "id": "2b1e0e8abcb8f2ac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "DataModule is a class that combines all the necessary functions to create data sets.\n",
    "\n",
    "`prepare_data` - downloads/loads data\n",
    "\n",
    "`setup` - divides data into training and test data\n",
    "\n",
    "`train_dataloader` and `val_dataloader` - return appropriate dataloaders"
   ],
   "id": "9eafc35ce8bf7ee4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T13:24:19.851013Z",
     "start_time": "2024-07-27T13:24:19.847863Z"
    }
   },
   "cell_type": "code",
   "source": "from torch.utils.data import DataLoader",
   "id": "a9ba0eea256c98c6",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T13:24:20.041863Z",
     "start_time": "2024-07-27T13:24:20.035751Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DigitsDatamodule(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size = 32):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        self.data = load_digits().data\n",
    "        self.targets = load_digits().target\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        self.train_X, self.test_X, self.train_y, self.test_y = train_test_split(\n",
    "            self.data,\n",
    "            self.targets,\n",
    "            train_size=0.8,\n",
    "            stratify=self.targets\n",
    "        )\n",
    "        \n",
    "        self.train_dataset = DigitsDataset(self.train_X, self.train_y)\n",
    "        self.test_dataset = DigitsDataset(self.test_X, self.test_y)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=True)\n"
   ],
   "id": "39cbbeff06cd2b15",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model",
   "id": "8ebe41d343ee856a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T13:24:20.380328Z",
     "start_time": "2024-07-27T13:24:20.376761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim"
   ],
   "id": "7d7120aeb18db7fc",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "https://pytorch-lightning.readthedocs.io/en/stable/starter/converting.html",
   "id": "478952806c4632bb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The `LightningModule` class combines the definitions of the model and the way it is trained\n",
    "\n",
    "`__init__` - contains definitions of layers used in the model\n",
    "\n",
    "`forward` - contains definitions of how the input passes through all layers\n",
    "\n",
    "`configure_optimizers` - creates and returns an optimizer\n",
    "\n",
    "`training_step` - implements model training from the perspective of one batch\n",
    "\n",
    "`validation_step` - implements model validation from the perspective of one batch"
   ],
   "id": "34d12bc1333c0fca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T13:24:21.294924Z",
     "start_time": "2024-07-27T13:24:21.288713Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DigitsModel(pl.LightningModule):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.loss_function = nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size, 100)\n",
    "        self.fc2 = nn.Linear(100, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        if not self.training:\n",
    "            out = F.softmax(out, dim=1)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters())\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch # returns x and y\n",
    "        outputs = self.forward(inputs.float()) # prediction\n",
    "        loss = self.loss_function(outputs, labels.long())\n",
    "        \n",
    "        self.log('train_loss', loss)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch # returns x and y\n",
    "        outputs = self.forward(inputs.float()) # prediction\n",
    "        loss = self.loss_function(outputs, labels)\n",
    "        \n",
    "        self.log('val_loss', loss)\n"
   ],
   "id": "5286c4d837698438",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training loop",
   "id": "88a187c11949bd65"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create a datamodule - it contains a training and validation set",
   "id": "329a60150df146dc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T19:01:25.635427Z",
     "start_time": "2024-07-27T19:01:25.632842Z"
    }
   },
   "cell_type": "code",
   "source": "data_module = DigitsDatamodule()",
   "id": "ab2b5bc576bc5869",
   "outputs": [],
   "execution_count": 94
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create a model - it contains the training logic",
   "id": "ed49b0f045b097ca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T13:24:22.268491Z",
     "start_time": "2024-07-27T13:24:22.264763Z"
    }
   },
   "cell_type": "code",
   "source": "model = DigitsModel(64, 10)",
   "id": "2d1c0d8a84746220",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create a trainer - an object in which we set training parameters such as the number of echoes, graphics card usage, etc.",
   "id": "b94c9f6e9e915ec9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T13:24:54.105806Z",
     "start_time": "2024-07-27T13:24:54.088339Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=100,\n",
    "    accelerator=\"gpu\",\n",
    "    log_every_n_steps=10,\n",
    ")"
   ],
   "id": "9f8529c6ccb8aaec",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We start the training with the `fit` method to which we provide the model and datamodule",
   "id": "ce388480fb24f6f2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T13:25:15.799929Z",
     "start_time": "2024-07-27T13:24:55.179928Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.fit(model, data_module)",
   "id": "335d1f72a98c7d44",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kubus\\my_projects\\pytorch_tutor\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type             | Params | Mode \n",
      "-----------------------------------------------------------\n",
      "0 | loss_function | CrossEntropyLoss | 0      | train\n",
      "1 | fc1           | Linear           | 6.5 K  | train\n",
      "2 | fc2           | Linear           | 1.0 K  | train\n",
      "-----------------------------------------------------------\n",
      "7.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.5 K     Total params\n",
      "0.030     Total estimated model params size (MB)\n",
      "C:\\Users\\Kubus\\my_projects\\pytorch_tutor\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4b4f52984e4e488e95bfd85bd7167167"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T13:27:16.391178Z",
     "start_time": "2024-07-27T13:26:57.538455Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install tensorboard",
   "id": "7988d782131fdc27",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorboard\n",
      "  Downloading tensorboard-2.17.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting absl-py>=0.4 (from tensorboard)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard)\n",
      "  Downloading grpcio-1.65.1-cp311-cp311-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard)\n",
      "  Downloading Markdown-3.6-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from tensorboard) (1.26.3)\n",
      "Collecting protobuf!=4.24.0,<5.0.0,>=3.19.6 (from tensorboard)\n",
      "  Downloading protobuf-4.25.4-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from tensorboard) (65.5.0)\n",
      "Requirement already satisfied: six>1.9 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from tensorboard) (1.16.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard)\n",
      "  Downloading werkzeug-3.0.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
      "Downloading tensorboard-2.17.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/5.5 MB 660.6 kB/s eta 0:00:09\n",
      "    --------------------------------------- 0.1/5.5 MB 787.7 kB/s eta 0:00:07\n",
      "    --------------------------------------- 0.1/5.5 MB 983.0 kB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.2/5.5 MB 919.0 kB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.2/5.5 MB 919.0 kB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.2/5.5 MB 656.9 kB/s eta 0:00:09\n",
      "   - -------------------------------------- 0.3/5.5 MB 787.7 kB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.3/5.5 MB 842.9 kB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.3/5.5 MB 787.7 kB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.3/5.5 MB 787.7 kB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.3/5.5 MB 787.7 kB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.3/5.5 MB 787.7 kB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.3/5.5 MB 583.1 kB/s eta 0:00:09\n",
      "   --- ------------------------------------ 0.4/5.5 MB 671.7 kB/s eta 0:00:08\n",
      "   --- ------------------------------------ 0.5/5.5 MB 777.1 kB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 0.6/5.5 MB 783.3 kB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 0.6/5.5 MB 789.8 kB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 0.7/5.5 MB 794.5 kB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 0.7/5.5 MB 846.4 kB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 0.8/5.5 MB 859.0 kB/s eta 0:00:06\n",
      "   ------ --------------------------------- 0.9/5.5 MB 902.6 kB/s eta 0:00:06\n",
      "   ------ --------------------------------- 0.9/5.5 MB 931.8 kB/s eta 0:00:05\n",
      "   ------- -------------------------------- 1.0/5.5 MB 948.7 kB/s eta 0:00:05\n",
      "   ------- -------------------------------- 1.1/5.5 MB 982.8 kB/s eta 0:00:05\n",
      "   -------- ------------------------------- 1.1/5.5 MB 997.1 kB/s eta 0:00:05\n",
      "   -------- ------------------------------- 1.2/5.5 MB 1.0 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 1.3/5.5 MB 1.0 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 1.4/5.5 MB 1.1 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 1.4/5.5 MB 1.1 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 1.5/5.5 MB 1.1 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 1.6/5.5 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 1.7/5.5 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 1.7/5.5 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 1.8/5.5 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 1.9/5.5 MB 1.2 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 2.0/5.5 MB 1.2 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 2.0/5.5 MB 1.2 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 2.1/5.5 MB 1.2 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 2.2/5.5 MB 1.2 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 2.2/5.5 MB 1.2 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 2.3/5.5 MB 1.2 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 2.4/5.5 MB 1.2 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 2.4/5.5 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 2.5/5.5 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 2.6/5.5 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 2.6/5.5 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 2.7/5.5 MB 1.2 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 2.8/5.5 MB 1.3 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 2.8/5.5 MB 1.3 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 2.9/5.5 MB 1.3 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 3.0/5.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 3.1/5.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 3.1/5.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 3.2/5.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 3.3/5.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 3.3/5.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 3.4/5.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 3.5/5.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 3.5/5.5 MB 1.3 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 3.6/5.5 MB 1.3 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 3.7/5.5 MB 1.3 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 3.7/5.5 MB 1.3 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 3.8/5.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 3.9/5.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 4.0/5.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 4.1/5.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 4.1/5.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 4.2/5.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 4.3/5.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 4.4/5.5 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 4.4/5.5 MB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 4.4/5.5 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 4.5/5.5 MB 1.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 4.6/5.5 MB 1.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 4.7/5.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 4.7/5.5 MB 1.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 4.8/5.5 MB 1.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 4.9/5.5 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.0/5.5 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.0/5.5 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 5.1/5.5 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 5.2/5.5 MB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.3/5.5 MB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.3/5.5 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.4/5.5 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.5/5.5 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 1.4 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "   ---------------------------------------- 0.0/133.7 kB ? eta -:--:--\n",
      "   ------------------ --------------------- 61.4/133.7 kB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 133.7/133.7 kB 2.0 MB/s eta 0:00:00\n",
      "Downloading grpcio-1.65.1-cp311-cp311-win_amd64.whl (4.1 MB)\n",
      "   ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/4.1 MB 991.0 kB/s eta 0:00:05\n",
      "    --------------------------------------- 0.1/4.1 MB 1.3 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.2/4.1 MB 1.6 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.2/4.1 MB 1.5 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.3/4.1 MB 1.4 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.4/4.1 MB 1.6 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 0.5/4.1 MB 1.5 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 0.5/4.1 MB 1.6 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 0.6/4.1 MB 1.6 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 0.7/4.1 MB 1.6 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 0.8/4.1 MB 1.6 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 0.8/4.1 MB 1.5 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 0.9/4.1 MB 1.5 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 0.9/4.1 MB 1.5 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 1.0/4.1 MB 1.5 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 1.0/4.1 MB 1.4 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 1.1/4.1 MB 1.4 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 1.2/4.1 MB 1.4 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 1.2/4.1 MB 1.4 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 1.2/4.1 MB 1.3 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 1.3/4.1 MB 1.3 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 1.4/4.1 MB 1.3 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 1.4/4.1 MB 1.4 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 1.5/4.1 MB 1.4 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 1.6/4.1 MB 1.4 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 1.6/4.1 MB 1.4 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 1.7/4.1 MB 1.4 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 1.8/4.1 MB 1.4 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 1.8/4.1 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 1.9/4.1 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 2.0/4.1 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 2.1/4.1 MB 1.4 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 2.1/4.1 MB 1.4 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 2.2/4.1 MB 1.4 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 2.3/4.1 MB 1.4 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 2.3/4.1 MB 1.4 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 2.4/4.1 MB 1.4 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 2.4/4.1 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 2.5/4.1 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 2.6/4.1 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 2.7/4.1 MB 1.4 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 2.7/4.1 MB 1.4 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 2.8/4.1 MB 1.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 2.9/4.1 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 3.0/4.1 MB 1.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 3.1/4.1 MB 1.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 3.1/4.1 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 3.2/4.1 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 3.3/4.1 MB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 3.3/4.1 MB 1.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 3.4/4.1 MB 1.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 3.5/4.1 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 3.6/4.1 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 3.6/4.1 MB 1.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 3.7/4.1 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 3.8/4.1 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 3.8/4.1 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 3.8/4.1 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 3.9/4.1 MB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 4.0/4.1 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.1/4.1 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.1/4.1 MB 1.5 MB/s eta 0:00:00\n",
      "Downloading Markdown-3.6-py3-none-any.whl (105 kB)\n",
      "   ---------------------------------------- 0.0/105.4 kB ? eta -:--:--\n",
      "   --------------------------- ------------ 71.7/105.4 kB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 105.4/105.4 kB 1.5 MB/s eta 0:00:00\n",
      "Downloading protobuf-4.25.4-cp310-abi3-win_amd64.whl (413 kB)\n",
      "   ---------------------------------------- 0.0/413.4 kB ? eta -:--:--\n",
      "   ------ --------------------------------- 71.7/413.4 kB 2.0 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 143.4/413.4 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 235.5/413.4 kB 1.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 317.4/413.4 kB 1.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 399.4/413.4 kB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 413.4/413.4 kB 1.6 MB/s eta 0:00:00\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading werkzeug-3.0.3-py3-none-any.whl (227 kB)\n",
      "   ---------------------------------------- 0.0/227.3 kB ? eta -:--:--\n",
      "   ---------- ----------------------------- 61.4/227.3 kB 1.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 143.4/227.3 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 227.3/227.3 kB 1.7 MB/s eta 0:00:00\n",
      "Installing collected packages: werkzeug, tensorboard-data-server, protobuf, markdown, grpcio, absl-py, tensorboard\n",
      "Successfully installed absl-py-2.1.0 grpcio-1.65.1 markdown-3.6 protobuf-4.25.4 tensorboard-2.17.0 tensorboard-data-server-0.7.2 werkzeug-3.0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T13:27:26.331213Z",
     "start_time": "2024-07-27T13:27:22.754797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=lightning_logs/"
   ],
   "id": "8f0095630efc8c6c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-47edd2b4a7b89d13\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-47edd2b4a7b89d13\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Saving the model",
   "id": "af6b780661e27ac8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T13:28:12.062198Z",
     "start_time": "2024-07-27T13:28:12.054941Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.save_checkpoint('model.ckpt')",
   "id": "c4a097c0c47071f5",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Loading the model",
   "id": "b6ed0ec0b4790792"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T13:46:34.571037Z",
     "start_time": "2024-07-27T13:46:34.534239Z"
    }
   },
   "cell_type": "code",
   "source": "new_model = DigitsModel.load_from_checkpoint('model.ckpt', input_size = 64, num_classes = 10)",
   "id": "7c98677eb4233612",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Metrics",
   "id": "6782a27b06defcc0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T13:47:07.564892Z",
     "start_time": "2024-07-27T13:47:05.417312Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install torchmetrics",
   "id": "2dc2838629ba9de3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchmetrics in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (1.4.0.post0)\n",
      "Requirement already satisfied: numpy>1.20.0 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from torchmetrics) (1.26.3)\n",
      "Requirement already satisfied: packaging>17.1 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from torchmetrics) (24.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from torchmetrics) (2.3.1+cu118)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from torchmetrics) (0.11.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (65.5.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (3.13.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (2024.2.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.10.0->torchmetrics) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.10.0->torchmetrics) (2021.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T13:48:27.233084Z",
     "start_time": "2024-07-27T13:48:27.229972Z"
    }
   },
   "cell_type": "code",
   "source": "import torchmetrics",
   "id": "1d1a1600e7675479",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We create metrics in the `__init__` function - it is important that training and validation metrics are a separate object\n",
    "\n",
    "Metrics are counted in the `training_step` and `validation_step` functions"
   ],
   "id": "31c057070ff4fc04"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T14:59:37.614009Z",
     "start_time": "2024-07-27T14:59:37.605571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DigitsModel(pl.LightningModule):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.loss_function = nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size, 100)\n",
    "        self.fc2 = nn.Linear(100, num_classes)\n",
    "        \n",
    "        self.train_accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes) # test metrics\n",
    "        self.val_accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes) # validation metrics\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        if not self.training:\n",
    "            out = F.softmax(out, dim=1)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters())\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        \n",
    "        outputs = self.forward(inputs.float())\n",
    "        loss = self.loss_function(outputs, labels.long())\n",
    "        \n",
    "        self.log('train_loss', loss)\n",
    "        \n",
    "        outputs = F.softmax(outputs, dim=1)\n",
    "        \n",
    "        self.train_accuracy(outputs, labels)\n",
    "        self.log('train_accuracy', self.train_accuracy, on_epoch=True, on_step=False) # displays the accuracy on the test set every epoch\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        \n",
    "        outputs = self.forward(inputs.float())\n",
    "        loss = self.loss_function(outputs, labels)\n",
    "        \n",
    "        self.log('val_loss', loss)\n",
    "        outputs = F.softmax(outputs, dim=1)\n",
    "        self.val_accuracy(outputs, labels)\n",
    "        self.log('val_accuracy', self.val_accuracy, on_epoch=True, on_step=False)\n",
    "        \n",
    "        return loss\n"
   ],
   "id": "8ee6ac1bd8bca96a",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T15:01:30.194929Z",
     "start_time": "2024-07-27T15:01:30.186471Z"
    }
   },
   "cell_type": "code",
   "source": "model_1 = DigitsModel(64, 10)",
   "id": "483d1b5671467541",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T15:23:35.387497Z",
     "start_time": "2024-07-27T15:23:35.359445Z"
    }
   },
   "cell_type": "code",
   "source": "trainer = pl.Trainer(max_epochs=100, accelerator=\"gpu\")",
   "id": "8e9d0e9aa782b5d4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T15:24:43.291205Z",
     "start_time": "2024-07-27T15:24:13.533334Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.fit(model_1, data_module)",
   "id": "86c0c90dc0fc39b1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kubus\\my_projects\\pytorch_tutor\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type               | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | loss_function  | CrossEntropyLoss   | 0      | train\n",
      "1 | fc1            | Linear             | 6.5 K  | train\n",
      "2 | fc2            | Linear             | 1.0 K  | train\n",
      "3 | train_accuracy | MulticlassAccuracy | 0      | train\n",
      "4 | val_accuracy   | MulticlassAccuracy | 0      | train\n",
      "--------------------------------------------------------------\n",
      "7.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.5 K     Total params\n",
      "0.030     Total estimated model params size (MB)\n",
      "C:\\Users\\Kubus\\my_projects\\pytorch_tutor\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "C:\\Users\\Kubus\\my_projects\\pytorch_tutor\\.venv\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:298: The number of training batches (45) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "822236b8e32b4b04a98857a2a184632e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T16:40:26.545744Z",
     "start_time": "2024-07-27T16:40:23.018795Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/\n"
   ],
   "id": "c8c2c21b03ec21ff",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-908aa7fa68a2c67b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-908aa7fa68a2c67b\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Additional metrics",
   "id": "a8ce26e022df7998"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T19:02:05.001026Z",
     "start_time": "2024-07-27T19:02:04.993220Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DigitsModel(pl.LightningModule):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.loss_function = nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size, 100)\n",
    "        self.fc2 = nn.Linear(100, num_classes)\n",
    "        \n",
    "        self.train_accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.val_accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        \n",
    "        self.train_macro_f1 = torchmetrics.F1Score(num_classes=num_classes, average='macro', task=\"multiclass\")\n",
    "        self.val_macro_f1 = torchmetrics.F1Score(num_classes=num_classes, average='macro', task=\"multiclass\")\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        if not self.training:\n",
    "            out = F.softmax(out, dim=1)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters())\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self.forward(inputs.float())\n",
    "        loss = self.loss_function(outputs, labels.long())\n",
    "        self.log('train_loss', loss)\n",
    "        \n",
    "        self.train_accuracy(outputs, labels)\n",
    "        self.log('train_accuracy', self.train_accuracy, on_epoch=True, on_step=False)\n",
    "        \n",
    "        self.train_macro_f1(outputs, labels)\n",
    "        self.log(\"train_macro_f1\", self.train_macro_f1, on_epoch=True, on_step=False)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        \n",
    "        outputs = self.forward(inputs.float())\n",
    "        loss = self.loss_function(outputs, labels.long())\n",
    "        self.log('val_loss', loss)\n",
    "        \n",
    "        self.val_accuracy(outputs, labels)\n",
    "        self.log('val_accuracy', self.val_accuracy, on_epoch=True, on_step=False)\n",
    "        \n",
    "        self.val_macro_f1(outputs, labels)\n",
    "        self.log(\"val_macro_f1\", self.val_macro_f1, on_epoch=True, on_step=False)\n",
    "        \n",
    "        return loss\n"
   ],
   "id": "32a389206cdca9de",
   "outputs": [],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T19:02:05.554456Z",
     "start_time": "2024-07-27T19:02:05.548762Z"
    }
   },
   "cell_type": "code",
   "source": "model = DigitsModel(64, 10)",
   "id": "26508c4919e604b",
   "outputs": [],
   "execution_count": 96
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T19:02:06.013343Z",
     "start_time": "2024-07-27T19:02:05.995148Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=100,\n",
    "    accelerator=\"gpu\",\n",
    ")"
   ],
   "id": "ba3dbd8c40fc183e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T19:02:39.766685Z",
     "start_time": "2024-07-27T19:02:06.801940Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.fit(model, data_module)",
   "id": "7c531b37c915e011",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kubus\\my_projects\\pytorch_tutor\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type               | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | loss_function  | CrossEntropyLoss   | 0      | train\n",
      "1 | fc1            | Linear             | 6.5 K  | train\n",
      "2 | fc2            | Linear             | 1.0 K  | train\n",
      "3 | train_accuracy | MulticlassAccuracy | 0      | train\n",
      "4 | val_accuracy   | MulticlassAccuracy | 0      | train\n",
      "5 | train_macro_f1 | MulticlassF1Score  | 0      | train\n",
      "6 | val_macro_f1   | MulticlassF1Score  | 0      | train\n",
      "--------------------------------------------------------------\n",
      "7.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.5 K     Total params\n",
      "0.030     Total estimated model params size (MB)\n",
      "C:\\Users\\Kubus\\my_projects\\pytorch_tutor\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "C:\\Users\\Kubus\\my_projects\\pytorch_tutor\\.venv\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:298: The number of training batches (45) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a9fcf8be5c7d47a1b1a9e1843989d4d1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    }
   ],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T19:02:59.099787Z",
     "start_time": "2024-07-27T19:02:59.086227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=lightning_logs/"
   ],
   "id": "53c205f86ba53e24",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 26572), started 5:35:33 ago. (Use '!kill 26572' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e983cc9dbffd884e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e983cc9dbffd884e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 99
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Tasks",
   "id": "b572d4cae5c5dcb7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The aim of the tasks is to create a model to detect whether a patient has diabetes based on laboratory results\n",
    "\n",
    "https://www.kaggle.com/datasets/akshaydattatraykhare/diabetes-dataset"
   ],
   "id": "b3ce9c9ee4a64d61"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Download data",
   "id": "dab65b44e9ce6ade"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T19:07:28.774520Z",
     "start_time": "2024-07-27T19:07:26.599950Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install requests",
   "id": "87a965c99667d65f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kubus\\my_projects\\pytorch_tutor\\.venv\\lib\\site-packages (from requests) (2024.7.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 101
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T19:07:36.575798Z",
     "start_time": "2024-07-27T19:07:36.556602Z"
    }
   },
   "cell_type": "code",
   "source": "!wget -O diabetes_data.csv https://pastebin.com/raw/qdrUE0E0",
   "id": "395b8f8cbcca04b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "execution_count": 102
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T17:10:24.251382Z",
     "start_time": "2024-07-28T17:10:22.450619Z"
    }
   },
   "cell_type": "code",
   "source": "import pandas as pd",
   "id": "54ddddb9df293db0",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T20:05:32.431964Z",
     "start_time": "2024-07-28T20:05:32.427217Z"
    }
   },
   "cell_type": "code",
   "source": "data = pd.read_csv('diabetes_data.csv')",
   "id": "8520278093db8807",
   "outputs": [],
   "execution_count": 217
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Visualization of the collection",
   "id": "79fa616707e5ca05"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We will try to predict the value of the `Outcome` column based on the values of laboratory results and patient characteristics - other columns",
   "id": "59484c204edde06d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T20:05:33.712901Z",
     "start_time": "2024-07-28T20:05:33.704106Z"
    }
   },
   "cell_type": "code",
   "source": "data",
   "id": "403b3bc3c6900d3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows  9 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 218
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T20:05:34.136562Z",
     "start_time": "2024-07-28T20:05:34.132913Z"
    }
   },
   "cell_type": "code",
   "source": "feature_columns = data.drop(columns=['Outcome'])",
   "id": "59f37eda2dca3fd6",
   "outputs": [],
   "execution_count": 219
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T20:05:34.613793Z",
     "start_time": "2024-07-28T20:05:34.604847Z"
    }
   },
   "cell_type": "code",
   "source": "feature_columns",
   "id": "83c4de137938400b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  \n",
       "0                       0.627   50  \n",
       "1                       0.351   31  \n",
       "2                       0.672   32  \n",
       "3                       0.167   21  \n",
       "4                       2.288   33  \n",
       "..                        ...  ...  \n",
       "763                     0.171   63  \n",
       "764                     0.340   27  \n",
       "765                     0.245   30  \n",
       "766                     0.349   47  \n",
       "767                     0.315   23  \n",
       "\n",
       "[768 rows x 8 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows  8 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 220
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We need to standardize the data for each column - subtract the mean and divide by the standard deviation",
   "id": "861ce82c924efee6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T20:05:35.713587Z",
     "start_time": "2024-07-28T20:05:35.699996Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def standardize(x):\n",
    "    x_std = x.copy(deep=True)\n",
    "    for c in feature_columns:\n",
    "        x_std[c] = (x_std[c] - x_std[c].mean()) / x_std[c].std()\n",
    "    \n",
    "    return x_std\n",
    "\n",
    "data = standardize(data)\n",
    "data.head()\n"
   ],
   "id": "12d5cef3d3febba4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Pregnancies   Glucose  BloodPressure  SkinThickness   Insulin       BMI  \\\n",
       "0     0.639530  0.847771       0.149543       0.906679 -0.692439  0.203880   \n",
       "1    -0.844335 -1.122665      -0.160441       0.530556 -0.692439 -0.683976   \n",
       "2     1.233077  1.942458      -0.263769      -1.287373 -0.692439 -1.102537   \n",
       "3    -0.844335 -0.997558      -0.160441       0.154433  0.123221 -0.493721   \n",
       "4    -1.141108  0.503727      -1.503707       0.906679  0.765337  1.408828   \n",
       "\n",
       "   DiabetesPedigreeFunction       Age  Outcome  \n",
       "0                  0.468187  1.425067        1  \n",
       "1                 -0.364823 -0.190548        0  \n",
       "2                  0.604004 -0.105515        1  \n",
       "3                 -0.920163 -1.040871        0  \n",
       "4                  5.481337 -0.020483        1  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.639530</td>\n",
       "      <td>0.847771</td>\n",
       "      <td>0.149543</td>\n",
       "      <td>0.906679</td>\n",
       "      <td>-0.692439</td>\n",
       "      <td>0.203880</td>\n",
       "      <td>0.468187</td>\n",
       "      <td>1.425067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.844335</td>\n",
       "      <td>-1.122665</td>\n",
       "      <td>-0.160441</td>\n",
       "      <td>0.530556</td>\n",
       "      <td>-0.692439</td>\n",
       "      <td>-0.683976</td>\n",
       "      <td>-0.364823</td>\n",
       "      <td>-0.190548</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.233077</td>\n",
       "      <td>1.942458</td>\n",
       "      <td>-0.263769</td>\n",
       "      <td>-1.287373</td>\n",
       "      <td>-0.692439</td>\n",
       "      <td>-1.102537</td>\n",
       "      <td>0.604004</td>\n",
       "      <td>-0.105515</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.844335</td>\n",
       "      <td>-0.997558</td>\n",
       "      <td>-0.160441</td>\n",
       "      <td>0.154433</td>\n",
       "      <td>0.123221</td>\n",
       "      <td>-0.493721</td>\n",
       "      <td>-0.920163</td>\n",
       "      <td>-1.040871</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.141108</td>\n",
       "      <td>0.503727</td>\n",
       "      <td>-1.503707</td>\n",
       "      <td>0.906679</td>\n",
       "      <td>0.765337</td>\n",
       "      <td>1.408828</td>\n",
       "      <td>5.481337</td>\n",
       "      <td>-0.020483</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 221
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T20:05:38.006053Z",
     "start_time": "2024-07-28T20:05:38.001359Z"
    }
   },
   "cell_type": "code",
   "source": "data.to_numpy()",
   "id": "b9b06307e6c1dfb4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.63953049,  0.84777132,  0.1495433 , ...,  0.46818687,\n",
       "         1.42506672,  1.        ],\n",
       "       [-0.84433482, -1.12266474, -0.16044119, ..., -0.36482303,\n",
       "        -0.19054773,  0.        ],\n",
       "       [ 1.23307662,  1.94245802, -0.26376935, ...,  0.6040037 ,\n",
       "        -0.10551539,  1.        ],\n",
       "       ...,\n",
       "       [ 0.34275743,  0.00329872,  0.1495433 , ..., -0.68474712,\n",
       "        -0.27558007,  0.        ],\n",
       "       [-0.84433482,  0.15968254, -0.47042568, ..., -0.37085933,\n",
       "         1.1699697 ,  1.        ],\n",
       "       [-0.84433482, -0.87245064,  0.04621514, ..., -0.4734765 ,\n",
       "        -0.87080644,  0.        ]])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 222
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Creates dataset and datamodule",
   "id": "795f757e1c45e26a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### a) Divide the data into input (x) and output (y):\n",
    "\n",
    "y - outcome column\n",
    "x - remaining columns\n",
    "\n",
    "Convert x and y to numpy"
   ],
   "id": "240b01254a61b1bc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T20:05:40.991036Z",
     "start_time": "2024-07-28T20:05:40.986865Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y = data[\"Outcome\"]\n",
    "x = data.drop(\"Outcome\", axis=1)"
   ],
   "id": "406a9a86c809385a",
   "outputs": [],
   "execution_count": 223
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T20:05:41.657739Z",
     "start_time": "2024-07-28T20:05:41.653608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "\n",
    "print(x)"
   ],
   "id": "6a5506dcc89e6dc0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.63953049  0.84777132  0.1495433  ...  0.20387991  0.46818687\n",
      "   1.42506672]\n",
      " [-0.84433482 -1.12266474 -0.16044119 ... -0.68397621 -0.36482303\n",
      "  -0.19054773]\n",
      " [ 1.23307662  1.94245802 -0.26376935 ... -1.10253696  0.6040037\n",
      "  -0.10551539]\n",
      " ...\n",
      " [ 0.34275743  0.00329872  0.1495433  ... -0.73471085 -0.68474712\n",
      "  -0.27558007]\n",
      " [-0.84433482  0.15968254 -0.47042568 ... -0.24004815 -0.37085933\n",
      "   1.1699697 ]\n",
      " [-0.84433482 -0.87245064  0.04621514 ... -0.20199718 -0.4734765\n",
      "  -0.87080644]]\n"
     ]
    }
   ],
   "execution_count": 224
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T20:05:42.840855Z",
     "start_time": "2024-07-28T20:05:42.837655Z"
    }
   },
   "cell_type": "code",
   "source": "from torch.utils.data import Dataset, DataLoader",
   "id": "b830076fdbfc64a6",
   "outputs": [],
   "execution_count": 225
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### b) Create dataset class",
   "id": "877167d742559600"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T20:05:47.584732Z",
     "start_time": "2024-07-28T20:05:47.581078Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DiabetesDataset(Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx]\n",
    "        y = self.targets[idx]\n",
    "        \n",
    "        return x, y\n"
   ],
   "id": "3f29ccf92341333b",
   "outputs": [],
   "execution_count": 226
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T20:05:48.636692Z",
     "start_time": "2024-07-28T20:05:48.633570Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = DiabetesDataset(x, y)",
   "id": "35a998abbd7ec6dc",
   "outputs": [],
   "execution_count": 227
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T20:05:49.127891Z",
     "start_time": "2024-07-28T20:05:49.125306Z"
    }
   },
   "cell_type": "code",
   "source": "sample_data, sample_target = dataset[0]",
   "id": "ca5fa6129ba6f8f",
   "outputs": [],
   "execution_count": 228
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T20:05:49.639499Z",
     "start_time": "2024-07-28T20:05:49.635876Z"
    }
   },
   "cell_type": "code",
   "source": "sample_data",
   "id": "1975abc323634b80",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.63953049,  0.84777132,  0.1495433 ,  0.90667906, -0.69243932,\n",
       "        0.20387991,  0.46818687,  1.42506672])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 229
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T20:05:50.476586Z",
     "start_time": "2024-07-28T20:05:50.472916Z"
    }
   },
   "cell_type": "code",
   "source": "sample_target",
   "id": "508e3449a5804c5a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 230
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### c) Create Datamodule class",
   "id": "6bb4b54f19bc8617"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The class should:\n",
    "* In the `prepare_data` method:\n",
    "    * load data from disk\n",
    "* In the `setup` method:\n",
    "    * standardize data\n",
    "    * divide into x and y\n",
    "    * divide into x and y into training and testing\n",
    "    * create training and test datasets from the DiabetesDataset class\n",
    "* In the `train_dataloader` method\n",
    "    * rip the dataloader for the training set\n",
    "* In the `val_dataloader` method\n",
    "    * return dataloader for validation set"
   ],
   "id": "a8fa7f42f14d3551"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T20:06:12.555026Z",
     "start_time": "2024-07-28T20:06:12.551888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pytorch_lightning as pl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader"
   ],
   "id": "11c77d333d947f20",
   "outputs": [],
   "execution_count": 231
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T20:06:13.024445Z",
     "start_time": "2024-07-28T20:06:13.018733Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DiabetesDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size = 32):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def prepare_data(self) -> None:\n",
    "        self.data = pd.read_csv('diabetes_data.csv')\n",
    "        \n",
    "    def _standardize(self, x):\n",
    "        x_std = x.copy(deep=True)\n",
    "        feature_columns = data.drop(columns=['Outcome'])\n",
    "    \n",
    "        for c in feature_columns:\n",
    "            x_std[c] = (x_std[c] - x_std[c].mean()) / x_std[c].std()\n",
    "        \n",
    "        return x_std\n",
    "    \n",
    "    def setup(self, stage = None):\n",
    "        data = self._standardize(self.data)\n",
    "        y = data[\"Outcome\"]\n",
    "        x = data.drop(\"Outcome\", axis=1)\n",
    "        \n",
    "        x = np.array(x)\n",
    "        y = np.array(y)\n",
    "        \n",
    "        train_X, test_X, train_y, test_y = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        self.train_dataset = DiabetesDataset(train_X, train_y)\n",
    "        self.test_dataset = DiabetesDataset(test_X, test_y)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False)\n"
   ],
   "id": "fb10f4f002b7fc02",
   "outputs": [],
   "execution_count": 232
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T20:06:13.913771Z",
     "start_time": "2024-07-28T20:06:13.910661Z"
    }
   },
   "cell_type": "code",
   "source": "data_module = DiabetesDataModule()",
   "id": "dc5fc869ce3739f4",
   "outputs": [],
   "execution_count": 233
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T20:06:14.690469Z",
     "start_time": "2024-07-28T20:06:14.685804Z"
    }
   },
   "cell_type": "code",
   "source": "data_module.prepare_data()",
   "id": "2f9da5e020b83e63",
   "outputs": [],
   "execution_count": 234
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T20:06:15.180152Z",
     "start_time": "2024-07-28T20:06:15.171737Z"
    }
   },
   "cell_type": "code",
   "source": "data_module.setup()",
   "id": "68229682b21eaa1",
   "outputs": [],
   "execution_count": 235
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Test - visualization of one batch",
   "id": "67cb35fd9dc557e0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T20:06:19.226431Z",
     "start_time": "2024-07-28T20:06:19.220557Z"
    }
   },
   "cell_type": "code",
   "source": "next(iter(data_module.train_dataloader()))[0].shape",
   "id": "ce6c77e8944b47cf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 8])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 236
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T20:06:20.345316Z",
     "start_time": "2024-07-28T20:06:20.340141Z"
    }
   },
   "cell_type": "code",
   "source": "next(iter(data_module.train_dataloader()))[1].shape",
   "id": "cc92c7edc7a54722",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 237
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create and train model",
   "id": "19ecbe3272938859"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Implement any neural network to solve the classification problem\n",
    "\n",
    "As error functions use binary cross entropp `BCELoss` since we are dealing with binary classification\n",
    "\n",
    "The sigmoid function should be used as the last activation function in the network\n",
    "\n",
    "Add a performance metric for the training and validation sets"
   ],
   "id": "1b5d86c24f3a4b2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T20:06:22.781279Z",
     "start_time": "2024-07-28T20:06:22.778151Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torchmetrics\n",
    "import torch"
   ],
   "id": "f496943e60a0c36",
   "outputs": [],
   "execution_count": 238
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T20:06:23.593357Z",
     "start_time": "2024-07-28T20:06:23.585973Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DiabetesNet(pl.LightningModule):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.loss_function = nn.BCELoss()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size, 100)\n",
    "        self.fc2 = nn.Linear(100, num_classes)\n",
    "        self.fc3 = nn.Linear(num_classes, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        self.train_accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.val_accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.sigmoid(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters())\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self.forward(inputs.float())\n",
    "        \n",
    "        loss = self.loss_function(outputs, labels)\n",
    "        self.log('train_loss', loss)\n",
    "        \n",
    "        self.train_accuracy(outputs, labels)\n",
    "        self.log('train_accuracy', self.train_accuracy, on_epoch=True, on_step=False)\n",
    "        \n",
    "        pred = torch.softmax(outputs, dim=1)\n",
    "        self.log(\"pred\", pred, on_epoch=True, on_step=False)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self.forward(inputs.float())\n",
    "        loss = self.loss_function(outputs, labels)\n",
    "        self.log('val_loss', loss)\n",
    "        \n",
    "        self.val_accuracy(outputs, labels)\n",
    "        self.log('val_accuracy', self.val_accuracy, on_epoch=True, on_step=False)\n",
    "        \n",
    "        pred = torch.softmax(outputs, dim=1)\n",
    "        self.log(\"pred\", pred, on_epoch=True, on_step=False)\n",
    "        \n",
    "        return loss\n"
   ],
   "id": "d5b8c97ce96cc6b2",
   "outputs": [],
   "execution_count": 239
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T20:06:24.571236Z",
     "start_time": "2024-07-28T20:06:24.567072Z"
    }
   },
   "cell_type": "code",
   "source": "model = DiabetesNet(8, 32)",
   "id": "a86f2bcd76579832",
   "outputs": [],
   "execution_count": 240
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T20:06:25.188744Z",
     "start_time": "2024-07-28T20:06:25.169367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=100,\n",
    "    accelerator=\"gpu\",\n",
    ")"
   ],
   "id": "fecd08b51b36830",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "execution_count": 241
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T20:06:26.901376Z",
     "start_time": "2024-07-28T20:06:26.731327Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.fit(model, data_module)",
   "id": "a476aa7339504a75",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type               | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | loss_function  | BCELoss            | 0      | train\n",
      "1 | fc1            | Linear             | 900    | train\n",
      "2 | fc2            | Linear             | 3.2 K  | train\n",
      "3 | fc3            | Linear             | 33     | train\n",
      "4 | sigmoid        | Sigmoid            | 0      | train\n",
      "5 | train_accuracy | MulticlassAccuracy | 0      | train\n",
      "6 | val_accuracy   | MulticlassAccuracy | 0      | train\n",
      "--------------------------------------------------------------\n",
      "4.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.2 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "172a2091aa18415b85f3f1a68a25e247"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kubus\\my_projects\\pytorch_tutor\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])) is deprecated. Please ensure they have the same size.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[242], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata_module\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\my_projects\\pytorch_tutor\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:543\u001B[0m, in \u001B[0;36mTrainer.fit\u001B[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[0;32m    541\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m=\u001B[39m TrainerStatus\u001B[38;5;241m.\u001B[39mRUNNING\n\u001B[0;32m    542\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m--> 543\u001B[0m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_and_handle_interrupt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    544\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_impl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatamodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\n\u001B[0;32m    545\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\my_projects\\pytorch_tutor\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:44\u001B[0m, in \u001B[0;36m_call_and_handle_interrupt\u001B[1;34m(trainer, trainer_fn, *args, **kwargs)\u001B[0m\n\u001B[0;32m     42\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     43\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher\u001B[38;5;241m.\u001B[39mlaunch(trainer_fn, \u001B[38;5;241m*\u001B[39margs, trainer\u001B[38;5;241m=\u001B[39mtrainer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m---> 44\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtrainer_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     46\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _TunerExitException:\n\u001B[0;32m     47\u001B[0m     _call_teardown_hook(trainer)\n",
      "File \u001B[1;32m~\\my_projects\\pytorch_tutor\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:579\u001B[0m, in \u001B[0;36mTrainer._fit_impl\u001B[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[0;32m    572\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    573\u001B[0m ckpt_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_checkpoint_connector\u001B[38;5;241m.\u001B[39m_select_ckpt_path(\n\u001B[0;32m    574\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn,\n\u001B[0;32m    575\u001B[0m     ckpt_path,\n\u001B[0;32m    576\u001B[0m     model_provided\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    577\u001B[0m     model_connected\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    578\u001B[0m )\n\u001B[1;32m--> 579\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mckpt_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    581\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstopped\n\u001B[0;32m    582\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32m~\\my_projects\\pytorch_tutor\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:986\u001B[0m, in \u001B[0;36mTrainer._run\u001B[1;34m(self, model, ckpt_path)\u001B[0m\n\u001B[0;32m    981\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_signal_connector\u001B[38;5;241m.\u001B[39mregister_signal_handlers()\n\u001B[0;32m    983\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[0;32m    984\u001B[0m \u001B[38;5;66;03m# RUN THE TRAINER\u001B[39;00m\n\u001B[0;32m    985\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[1;32m--> 986\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_stage\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    988\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[0;32m    989\u001B[0m \u001B[38;5;66;03m# POST-Training CLEAN UP\u001B[39;00m\n\u001B[0;32m    990\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[0;32m    991\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: trainer tearing down\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\my_projects\\pytorch_tutor\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1028\u001B[0m, in \u001B[0;36mTrainer._run_stage\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1026\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining:\n\u001B[0;32m   1027\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m isolate_rng():\n\u001B[1;32m-> 1028\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_sanity_check\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1029\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mset_detect_anomaly(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_detect_anomaly):\n\u001B[0;32m   1030\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit_loop\u001B[38;5;241m.\u001B[39mrun()\n",
      "File \u001B[1;32m~\\my_projects\\pytorch_tutor\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1057\u001B[0m, in \u001B[0;36mTrainer._run_sanity_check\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1054\u001B[0m call\u001B[38;5;241m.\u001B[39m_call_callback_hooks(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mon_sanity_check_start\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1056\u001B[0m \u001B[38;5;66;03m# run eval step\u001B[39;00m\n\u001B[1;32m-> 1057\u001B[0m \u001B[43mval_loop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1059\u001B[0m call\u001B[38;5;241m.\u001B[39m_call_callback_hooks(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mon_sanity_check_end\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1061\u001B[0m \u001B[38;5;66;03m# reset logger connector\u001B[39;00m\n",
      "File \u001B[1;32m~\\my_projects\\pytorch_tutor\\.venv\\Lib\\site-packages\\pytorch_lightning\\loops\\utilities.py:182\u001B[0m, in \u001B[0;36m_no_grad_context.<locals>._decorator\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    180\u001B[0m     context_manager \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mno_grad\n\u001B[0;32m    181\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m context_manager():\n\u001B[1;32m--> 182\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mloop_run\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\my_projects\\pytorch_tutor\\.venv\\Lib\\site-packages\\pytorch_lightning\\loops\\evaluation_loop.py:135\u001B[0m, in \u001B[0;36m_EvaluationLoop.run\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    133\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_progress\u001B[38;5;241m.\u001B[39mis_last_batch \u001B[38;5;241m=\u001B[39m data_fetcher\u001B[38;5;241m.\u001B[39mdone\n\u001B[0;32m    134\u001B[0m     \u001B[38;5;66;03m# run step hooks\u001B[39;00m\n\u001B[1;32m--> 135\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_evaluation_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataloader_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataloader_iter\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    136\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[0;32m    137\u001B[0m     \u001B[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001B[39;00m\n\u001B[0;32m    138\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32m~\\my_projects\\pytorch_tutor\\.venv\\Lib\\site-packages\\pytorch_lightning\\loops\\evaluation_loop.py:396\u001B[0m, in \u001B[0;36m_EvaluationLoop._evaluation_step\u001B[1;34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001B[0m\n\u001B[0;32m    390\u001B[0m hook_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_step\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mtesting \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalidation_step\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    391\u001B[0m step_args \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    392\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_step_args_from_hook_kwargs(hook_kwargs, hook_name)\n\u001B[0;32m    393\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m using_dataloader_iter\n\u001B[0;32m    394\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m (dataloader_iter,)\n\u001B[0;32m    395\u001B[0m )\n\u001B[1;32m--> 396\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_strategy_hook\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhook_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mstep_args\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    398\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_progress\u001B[38;5;241m.\u001B[39mincrement_processed()\n\u001B[0;32m    400\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m using_dataloader_iter:\n\u001B[0;32m    401\u001B[0m     \u001B[38;5;66;03m# update the hook kwargs now that the step method might have consumed the iterator\u001B[39;00m\n",
      "File \u001B[1;32m~\\my_projects\\pytorch_tutor\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:311\u001B[0m, in \u001B[0;36m_call_strategy_hook\u001B[1;34m(trainer, hook_name, *args, **kwargs)\u001B[0m\n\u001B[0;32m    308\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    310\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mprofile(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[Strategy]\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhook_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m--> 311\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    313\u001B[0m \u001B[38;5;66;03m# restore current_fx when nested context\u001B[39;00m\n\u001B[0;32m    314\u001B[0m pl_module\u001B[38;5;241m.\u001B[39m_current_fx_name \u001B[38;5;241m=\u001B[39m prev_fx_name\n",
      "File \u001B[1;32m~\\my_projects\\pytorch_tutor\\.venv\\Lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:411\u001B[0m, in \u001B[0;36mStrategy.validation_step\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    409\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module:\n\u001B[0;32m    410\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_redirection(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalidation_step\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m--> 411\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlightning_module\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalidation_step\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[239], line 46\u001B[0m, in \u001B[0;36mDiabetesNet.validation_step\u001B[1;34m(self, batch, batch_idx)\u001B[0m\n\u001B[0;32m     44\u001B[0m inputs, labels \u001B[38;5;241m=\u001B[39m batch\n\u001B[0;32m     45\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward(inputs\u001B[38;5;241m.\u001B[39mfloat())\n\u001B[1;32m---> 46\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloss_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlog(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_loss\u001B[39m\u001B[38;5;124m'\u001B[39m, loss)\n\u001B[0;32m     49\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mval_accuracy(outputs, labels)\n",
      "File \u001B[1;32m~\\my_projects\\pytorch_tutor\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\my_projects\\pytorch_tutor\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\my_projects\\pytorch_tutor\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:618\u001B[0m, in \u001B[0;36mBCELoss.forward\u001B[1;34m(self, input, target)\u001B[0m\n\u001B[0;32m    617\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor, target: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 618\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbinary_cross_entropy\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduction\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreduction\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\my_projects\\pytorch_tutor\\.venv\\Lib\\site-packages\\torch\\nn\\functional.py:3145\u001B[0m, in \u001B[0;36mbinary_cross_entropy\u001B[1;34m(input, target, weight, size_average, reduce, reduction)\u001B[0m\n\u001B[0;32m   3143\u001B[0m     reduction_enum \u001B[38;5;241m=\u001B[39m _Reduction\u001B[38;5;241m.\u001B[39mget_enum(reduction)\n\u001B[0;32m   3144\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m target\u001B[38;5;241m.\u001B[39msize() \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39msize():\n\u001B[1;32m-> 3145\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   3146\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUsing a target size (\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m) that is different to the input size (\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m) is deprecated. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   3147\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPlease ensure they have the same size.\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(target\u001B[38;5;241m.\u001B[39msize(), \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39msize())\n\u001B[0;32m   3148\u001B[0m     )\n\u001B[0;32m   3150\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   3151\u001B[0m     new_size \u001B[38;5;241m=\u001B[39m _infer_size(target\u001B[38;5;241m.\u001B[39msize(), weight\u001B[38;5;241m.\u001B[39msize())\n",
      "\u001B[1;31mValueError\u001B[0m: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])) is deprecated. Please ensure they have the same size."
     ]
    }
   ],
   "execution_count": 242
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7a619cd08130b934"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
