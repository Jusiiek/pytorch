{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torch-2.3.1%2Bcu118-cp311-cp311-linux_x86_64.whl (839.7 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m839.7/839.7 MB\u001B[0m \u001B[31m1.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:14\u001B[0m\n",
      "\u001B[?25hCollecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.18.1%2Bcu118-cp311-cp311-linux_x86_64.whl (6.3 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m6.3/6.3 MB\u001B[0m \u001B[31m1.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m0m\n",
      "\u001B[?25hCollecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.3.1%2Bcu118-cp311-cp311-linux_x86_64.whl (3.3 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.3/3.3 MB\u001B[0m \u001B[31m1.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\n",
      "\u001B[?25hCollecting filelock (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./.venv/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Collecting sympy (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m5.7/5.7 MB\u001B[0m \u001B[31m1.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hCollecting networkx (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.6/1.6 MB\u001B[0m \u001B[31m1.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\n",
      "\u001B[?25hCollecting jinja2 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m133.2/133.2 kB\u001B[0m \u001B[31m1.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\n",
      "\u001B[?25hCollecting fsspec (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m170.9/170.9 kB\u001B[0m \u001B[31m1.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\n",
      "\u001B[?25hCollecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m23.2/23.2 MB\u001B[0m \u001B[31m1.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hCollecting nvidia-cuda-runtime-cu11==11.8.89 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m875.6/875.6 kB\u001B[0m \u001B[31m1.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\n",
      "\u001B[?25hCollecting nvidia-cuda-cupti-cu11==11.8.87 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m13.1/13.1 MB\u001B[0m \u001B[31m1.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hCollecting nvidia-cudnn-cu11==8.7.0.84 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-8.7.0.84-py3-none-manylinux1_x86_64.whl (728.5 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m728.5/728.5 MB\u001B[0m \u001B[31m727.4 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:25\u001B[0m\n",
      "\u001B[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n",
      "\u001B[2K     \u001B[91m━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m130.5/417.9 MB\u001B[0m \u001B[31m565.1 kB/s\u001B[0m eta \u001B[36m0:08:29\u001B[0m\n",
      "\u001B[?25h\u001B[31mERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/Documents/my_projects/pytorch_tutor/.venv/lib/python3.11/site-packages/pip/_vendor/urllib3/response.py\", line 438, in _error_catcher\n",
      "    yield\n",
      "  File \"/home/Documents/my_projects/pytorch_tutor/.venv/lib/python3.11/site-packages/pip/_vendor/urllib3/response.py\", line 561, in read\n",
      "    data = self._fp_read(amt) if not fp_closed else b\"\"\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/Documents/my_projects/pytorch_tutor/.venv/lib/python3.11/site-packages/pip/_vendor/urllib3/response.py\", line 527, in _fp_read\n",
      "    return self._fp.read(amt) if amt is not None else self._fp.read()\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/Documents/my_projects/pytorch_tutor/.venv/lib/python3.11/site-packages/pip/_vendor/cachecontrol/filewrapper.py\", line 98, in read\n",
      "    data: bytes = self.__fp.read(amt)\n",
      "                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.pyenv/versions/3.11.9/lib/python3.11/http/client.py\", line 473, in read\n",
      "    s = self.fp.read(amt)\n",
      "        ^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.pyenv/versions/3.11.9/lib/python3.11/socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.pyenv/versions/3.11.9/lib/python3.11/ssl.py\", line 1314, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.pyenv/versions/3.11.9/lib/python3.11/ssl.py\", line 1166, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/Documents/my_projects/pytorch_tutor/.venv/lib/python3.11/site-packages/pip/_internal/cli/base_command.py\", line 180, in exc_logging_wrapper\n",
      "    status = run_func(*args)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/Documents/my_projects/pytorch_tutor/.venv/lib/python3.11/site-packages/pip/_internal/cli/req_command.py\", line 245, in wrapper\n",
      "    return func(self, options, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/Documents/my_projects/pytorch_tutor/.venv/lib/python3.11/site-packages/pip/_internal/commands/install.py\", line 377, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "                      ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/Documents/my_projects/pytorch_tutor/.venv/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 95, in resolve\n",
      "    result = self._result = resolver.resolve(\n",
      "                            ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/Documents/my_projects/pytorch_tutor/.venv/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py\", line 546, in resolve\n",
      "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/Documents/my_projects/pytorch_tutor/.venv/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py\", line 427, in resolve\n",
      "    failure_causes = self._attempt_to_pin_criterion(name)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/Documents/my_projects/pytorch_tutor/.venv/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py\", line 239, in _attempt_to_pin_criterion\n",
      "    criteria = self._get_updated_criteria(candidate)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/Documents/my_projects/pytorch_tutor/.venv/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py\", line 230, in _get_updated_criteria\n",
      "    self._add_to_criteria(criteria, requirement, parent=candidate)\n",
      "  File \"/home/Documents/my_projects/pytorch_tutor/.venv/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py\", line 173, in _add_to_criteria\n",
      "    if not criterion.candidates:\n",
      "  File \"/home/Documents/my_projects/pytorch_tutor/.venv/lib/python3.11/site-packages/pip/_vendor/resolvelib/structs.py\", line 156, in __bool__\n",
      "    return bool(self._sequence)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/Documents/my_projects/pytorch_tutor/.venv/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 155, in __bool__\n",
      "    return any(self)\n",
      "           ^^^^^^^^^\n",
      "  File \"/home/Documents/my_projects/pytorch_tutor/.venv/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 143, in <genexpr>\n",
      "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/Documents/my_projects/pytorch_tutor/.venv/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 47, in _iter_built\n",
      "    candidate = func()\n",
      "                ^^^^^^\n",
      "  File \"/home/Documents/my_projects/pytorch_tutor/.venv/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/factory.py\", line 182, in _make_candidate_from_link\n",
      "    base: Optional[BaseCandidate] = self._make_base_candidate_from_link(\n",
      "                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/Documents/my_projects/pytorch_tutor/.venv/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/factory.py\", line 228, in _make_base_candidate_from_link\n",
      "    self._link_candidate_cache[link] = LinkCandidate(\n",
      "                                       ^^^^^^^^^^^^^^\n",
      "  File \"/home/Documents/my_projects/pytorch_tutor/.venv/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 290, in __init__\n",
      "    super().__init__(\n",
      "  File \"/home/Documents/my_projects/pytorch_tutor/.venv/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 156, in __init__\n",
      "    self.dist = self._prepare()\n",
      "                ^^^^^^^^^^^^^^^\n",
      "  File \"/home/Documents/my_projects/pytorch_tutor/.venv/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 222, in _prepare\n",
      "    dist = self._prepare_distribution()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/Documents/my_projects/pytorch_tutor/.venv/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 301, in _prepare_distribution\n",
      "    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/Documents/my_projects/pytorch_tutor/.venv/lib/python3.11/site-packages/pip/_internal/operations/prepare.py\", line 525, in prepare_linked_requirement\n",
      "    return self._prepare_linked_requirement(req, parallel_builds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/Documents/my_projects/pytorch_tutor/.venv/lib/python3.11/site-packages/pip/_internal/operations/prepare.py\", line 596, in _prepare_linked_requirement\n",
      "    local_file = unpack_url(\n",
      "                 ^^^^^^^^^^^\n",
      "  File \"/home/Documents/my_projects/pytorch_tutor/.venv/lib/python3.11/site-packages/pip/_internal/operations/prepare.py\", line 168, in unpack_url\n",
      "    file = get_http_url(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/Documents/my_projects/pytorch_tutor/.venv/lib/python3.11/site-packages/pip/_internal/operations/prepare.py\", line 109, in get_http_url\n",
      "    from_path, content_type = download(link, temp_dir.path)\n",
      "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/Documents/my_projects/pytorch_tutor/.venv/lib/python3.11/site-packages/pip/_internal/network/download.py\", line 147, in __call__\n",
      "    for chunk in chunks:\n",
      "  File \"/home/Documents/my_projects/pytorch_tutor/.venv/lib/python3.11/site-packages/pip/_internal/cli/progress_bars.py\", line 53, in _rich_progress_bar\n",
      "    for chunk in iterable:\n",
      "  File \"/home/Documents/my_projects/pytorch_tutor/.venv/lib/python3.11/site-packages/pip/_internal/network/utils.py\", line 63, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "  File \"/home/Documents/my_projects/pytorch_tutor/.venv/lib/python3.11/site-packages/pip/_vendor/urllib3/response.py\", line 622, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/Documents/my_projects/pytorch_tutor/.venv/lib/python3.11/site-packages/pip/_vendor/urllib3/response.py\", line 560, in read\n",
      "    with self._error_catcher():\n",
      "  File \"/root/.pyenv/versions/3.11.9/lib/python3.11/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"/home/Documents/my_projects/pytorch_tutor/.venv/lib/python3.11/site-packages/pip/_vendor/urllib3/response.py\", line 443, in _error_catcher\n",
      "    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\n",
      "pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='download.pytorch.org', port=443): Read timed out.\u001B[0m\u001B[31m\n",
      "\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.0\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.1.2\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1D tensor = vector\n",
    "2d tesoor = matrix etc\n",
    "Tensors can have any number of dimensions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T18:32:56.106512Z",
     "start_time": "2024-07-14T18:32:50.795275Z"
    }
   },
   "source": "import torch",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[6.6609e-27, 4.5881e-41, 6.6609e-27, 4.5881e-41],\n",
       "         [1.1095e+27, 1.7250e+19, 2.9393e+29, 7.2133e+22],\n",
       "         [5.1454e+31, 2.3073e-12, 1.9049e+17, 2.0190e-19]],\n",
       "\n",
       "        [[1.1815e+22, 7.3971e+20, 2.7367e+20, 3.7399e-14],\n",
       "         [2.0190e-19, 1.3563e-19, 5.0746e+31, 2.0995e+17],\n",
       "         [1.3563e-19, 1.3563e-19, 1.3563e-19, 7.7781e+31]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.Tensor(2, 3, 4)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.Tensor allocates memory for the tensor but fills its value by reusing the values stored in memory (randomly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Popular methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(2, 3, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(2, 3, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Random values from 0 to 1 (uniform distribution)"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T19:17:21.961451Z",
     "start_time": "2024-07-10T19:17:21.951599Z"
    }
   },
   "source": [
    "torch.rand(2, 3 , 4)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6562, 0.0822, 0.0935, 0.4528],\n",
       "         [0.4686, 0.6261, 0.2374, 0.7174],\n",
       "         [0.2115, 0.7098, 0.7499, 0.0300]],\n",
       "\n",
       "        [[0.2082, 0.3361, 0.6901, 0.2722],\n",
       "         [0.6555, 0.8008, 0.6080, 0.1909],\n",
       "         [0.1077, 0.5430, 0.7184, 0.8134]]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Random values from 0 to 1 (normal distribution)"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T19:19:08.021566Z",
     "start_time": "2024-07-10T19:19:08.016938Z"
    }
   },
   "cell_type": "code",
   "source": "torch.randn(2, 3, 4)",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5690,  0.0181, -0.9221, -0.0086],\n",
       "         [-1.2049,  0.2661,  1.9103, -0.4978],\n",
       "         [ 1.8383,  0.4942,  0.8108, -1.9677]],\n",
       "\n",
       "        [[-0.1711,  0.2299,  0.6891, -0.0208],\n",
       "         [-1.6103, -0.2662,  0.2561, -0.2173],\n",
       "         [-0.0426,  1.8713, -2.1327, -0.5502]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Existing values"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T19:19:40.044746Z",
     "start_time": "2024-07-10T19:19:40.039133Z"
    }
   },
   "cell_type": "code",
   "source": "torch.Tensor([1,2,3])",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T19:19:48.943174Z",
     "start_time": "2024-07-10T19:19:48.937571Z"
    }
   },
   "cell_type": "code",
   "source": "torch.Tensor([[1,2,3],[4,5,6]])",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Change shapes"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T19:21:56.969128Z",
     "start_time": "2024-07-10T19:21:56.965573Z"
    }
   },
   "cell_type": "code",
   "source": "x = torch.Tensor([[1,2,3],[4,5,6]])",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T19:21:58.555680Z",
     "start_time": "2024-07-10T19:21:58.550850Z"
    }
   },
   "cell_type": "code",
   "source": "x.shape",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "to change a tensor shape use `.view()` method"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "`.view(-1)` flatten the tensor"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T19:25:07.688537Z",
     "start_time": "2024-07-10T19:25:07.682779Z"
    }
   },
   "cell_type": "code",
   "source": "x.view(3,2)",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.],\n",
       "        [5., 6.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T19:25:15.708205Z",
     "start_time": "2024-07-10T19:25:15.703031Z"
    }
   },
   "cell_type": "code",
   "source": "x.view(2,-1)",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Example operations on tensors"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T19:26:15.683280Z",
     "start_time": "2024-07-10T19:26:15.679666Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x1 = torch.Tensor([1,2,3])\n",
    "x2 = torch.Tensor([4,5,6])"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T19:26:22.945797Z",
     "start_time": "2024-07-10T19:26:22.940146Z"
    }
   },
   "cell_type": "code",
   "source": "x1 + x2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 7., 9.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Multiplication (element with element)"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T19:26:47.908084Z",
     "start_time": "2024-07-10T19:26:47.902624Z"
    }
   },
   "cell_type": "code",
   "source": "x1 * x2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4., 10., 18.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Matrix multiplication"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T19:27:14.471357Z",
     "start_time": "2024-07-10T19:27:14.467789Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x3 = torch.rand(2,2)\n",
    "x4 = torch.rand(2,2)"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T19:27:20.357597Z",
     "start_time": "2024-07-10T19:27:20.352933Z"
    }
   },
   "cell_type": "code",
   "source": "x3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7343, 0.3965],\n",
       "        [0.2801, 0.3097]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T19:27:22.485262Z",
     "start_time": "2024-07-10T19:27:22.479140Z"
    }
   },
   "cell_type": "code",
   "source": "x4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1615, 0.5006],\n",
       "        [0.3332, 0.6808]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T19:27:29.720580Z",
     "start_time": "2024-07-10T19:27:29.627801Z"
    }
   },
   "cell_type": "code",
   "source": "torch.matmul(x3,x4)",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2507, 0.6376],\n",
       "        [0.1484, 0.3510]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T19:27:35.908421Z",
     "start_time": "2024-07-10T19:27:35.903320Z"
    }
   },
   "cell_type": "code",
   "source": "torch.mm(x3,x4)\n",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2507, 0.6376],\n",
       "        [0.1484, 0.3510]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T19:27:40.609258Z",
     "start_time": "2024-07-10T19:27:40.604561Z"
    }
   },
   "cell_type": "code",
   "source": "x3 @ x4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2507, 0.6376],\n",
       "        [0.1484, 0.3510]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Computational graphs"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The main reason for using tensors in deep evaluation is that they allow us to automatically calculate the derivatives/gradients of functions (derivative for a scalar, gradient for many variables).\n",
    "\n",
    "This allows us to calculate the derivative of the neural network weights\n",
    "\n",
    "By performing operations on tensors, we create a **computational graph**. This graph illustrates how to obtain the result from the input values.\n",
    "\n",
    "Pytorch works on the **define-by-run** principle, which means that the computational graph will be created automatically if we perform calculations."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### tensors gradient"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T19:28:39.833688Z",
     "start_time": "2024-07-10T19:28:39.830065Z"
    }
   },
   "cell_type": "code",
   "source": "x = torch.Tensor(2,3,4)",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T19:28:44.238728Z",
     "start_time": "2024-07-10T19:28:44.235144Z"
    }
   },
   "cell_type": "code",
   "source": "x.requires_grad",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T19:28:48.849270Z",
     "start_time": "2024-07-10T19:28:48.845683Z"
    }
   },
   "cell_type": "code",
   "source": "x.requires_grad = True",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T19:28:49.521319Z",
     "start_time": "2024-07-10T19:28:49.516594Z"
    }
   },
   "cell_type": "code",
   "source": "x.requires_grad",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Example"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T19:29:25.705015Z",
     "start_time": "2024-07-10T19:29:25.701967Z"
    }
   },
   "cell_type": "code",
   "source": "x = torch.arange(3, dtype=torch.float32, requires_grad=True)",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T19:29:27.461375Z",
     "start_time": "2024-07-10T19:29:27.457303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "a = x + 2\n",
    "b = a ** 2\n",
    "c = b + 3\n",
    "y = c.mean()\n",
    "print(y)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12.6667, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We see that the `y` tensor \"remembers\" the operation that was used to obtain it and saves its gradient functions in the `grad_fn` parameter. If we set `requires_grad= True` on the input data, all tensors obtained from them will have gradient functions"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Calculating gradients"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Gradient counting is done using the `.backward()` function applied to the output.\n",
    "This function counts backpropagation over the entire graph, counting the gradients from the end of the graph to the beginning."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![image.png](data:image/png;base64,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)"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T19:30:42.324252Z",
     "start_time": "2024-07-10T19:30:42.306325Z"
    }
   },
   "cell_type": "code",
   "source": "y.backward()",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "After counting the gradients, we can obtain their values using the `.grad` attribute"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T19:32:05.903447Z",
     "start_time": "2024-07-10T19:32:05.899353Z"
    }
   },
   "cell_type": "code",
   "source": "x.grad",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.3333, 2.0000, 2.6667])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Graphics card usage"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "`torch.cuda.is_available()` function checks whether a graphics card is available"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T19:36:28.626386Z",
     "start_time": "2024-07-10T19:36:28.621280Z"
    }
   },
   "cell_type": "code",
   "source": "torch.cuda.is_available()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T19:36:33.110659Z",
     "start_time": "2024-07-10T19:36:33.107101Z"
    }
   },
   "cell_type": "code",
   "source": "x.device",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "To transfer tensors from cpu to gpu and vice versa we use the `.to()` function"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "CPU"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T19:37:16.891736Z",
     "start_time": "2024-07-10T19:37:16.887625Z"
    }
   },
   "cell_type": "code",
   "source": "torch.device('cpu')",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "GPU"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T19:37:38.425319Z",
     "start_time": "2024-07-10T19:37:38.420625Z"
    }
   },
   "cell_type": "code",
   "source": "torch.device('cuda')",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "transfer to GPU"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T19:38:02.847936Z",
     "start_time": "2024-07-10T19:37:59.965701Z"
    }
   },
   "cell_type": "code",
   "source": "x.to(torch.device('cuda'))",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2.], device='cuda:0', grad_fn=<ToCopyBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dynamically checks whether the graphics card is available, if not, CPU usage"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T19:38:31.557219Z",
     "start_time": "2024-07-10T19:38:31.553177Z"
    }
   },
   "cell_type": "code",
   "source": "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T19:38:38.307837Z",
     "start_time": "2024-07-10T19:38:38.303225Z"
    }
   },
   "cell_type": "code",
   "source": "device",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T19:38:39.361849Z",
     "start_time": "2024-07-10T19:38:39.358781Z"
    }
   },
   "cell_type": "code",
   "source": "x = x.to(device)",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Tensor to numpy"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T20:09:40.900884Z",
     "start_time": "2024-07-10T20:09:40.897681Z"
    }
   },
   "cell_type": "code",
   "source": "x =  torch.Tensor(2,3)",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T20:10:01.292630Z",
     "start_time": "2024-07-10T20:10:01.287949Z"
    }
   },
   "cell_type": "code",
   "source": "x.numpy()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.   , 1.875, 0.   ],\n",
       "       [2.   , 0.   , 2.125]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "To convert the tensor that is GPU, we must first transfer it to the CPU"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T20:11:05.541741Z",
     "start_time": "2024-07-10T20:11:05.538167Z"
    }
   },
   "cell_type": "code",
   "source": "x = torch.Tensor(2,3).to(device)",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T20:11:14.772953Z",
     "start_time": "2024-07-10T20:11:14.568873Z"
    }
   },
   "cell_type": "code",
   "source": "x.numpy()",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[38], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnumpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mTypeError\u001B[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T20:11:20.706205Z",
     "start_time": "2024-07-10T20:11:20.701051Z"
    }
   },
   "cell_type": "code",
   "source": "x.cpu().numpy()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.3185646e+33, 1.1868998e-42, 0.0000000e+00],\n",
       "       [2.0000000e+00, 0.0000000e+00, 2.0156250e+00]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "To convert a tensor that requires gradients, we must first detach it from the computation graph using the `.detach()` function"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T20:24:23.995093Z",
     "start_time": "2024-07-10T20:24:23.992242Z"
    }
   },
   "cell_type": "code",
   "source": "x = torch.Tensor(2,3)",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T20:24:25.646887Z",
     "start_time": "2024-07-10T20:24:25.643533Z"
    }
   },
   "cell_type": "code",
   "source": "x.requires_grad =  True",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T20:24:32.460883Z",
     "start_time": "2024-07-10T20:24:32.448690Z"
    }
   },
   "cell_type": "code",
   "source": "x.numpy()",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[42], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnumpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T20:24:37.526221Z",
     "start_time": "2024-07-10T20:24:37.521782Z"
    }
   },
   "cell_type": "code",
   "source": "x.detach().numpy()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.3184606e+33, 1.1868998e-42, 0.0000000e+00],\n",
       "       [2.3125000e+00, 0.0000000e+00, 2.3750000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Exercises"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Implement feed forward algorithm"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Implement the feed forward algorithm\n",
    "Implement the feed forward algorithm for a network with two layers\n",
    "* the network input has a size of 784\n",
    "* the first layer should have 100 neurons\n",
    "* the second (output) layer should have 10 neurons\n",
    "\n",
    "Batch size is 64 (but this does not affect the size of the scales)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T20:17:38.019887Z",
     "start_time": "2024-07-14T20:17:38.016840Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dimensions = [784, 100, 10]\n",
    "batch_size = 64"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T20:17:38.400230Z",
     "start_time": "2024-07-14T20:17:38.396633Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = torch.randn(dimensions[0], batch_size)\n",
    "y = torch.randn(dimensions[-1], batch_size)"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Initialize weights and bias"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Initialize the weights and biases for the layers by normally distributed  using the `torch.randn()` function."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "dimensions[1] is 100 (number of neurons in the hidden layer).\n",
    "dimensions[0] is 784 (number of neurons in the input layer).\n",
    "Therefore, weight_1 has shape (100, 784)."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "For weight_1, you need to transform data from the input layer (with 784 features) to the hidden layer (with 100 neurons). Hence, weight_1 should have dimensions (100, 784), ensuring each of the 100 neurons in the hidden layer is connected to all 784 input features."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T20:27:32.867099Z",
     "start_time": "2024-07-14T20:27:32.862418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "weight_1 = torch.randn(dimensions[1], dimensions[0], requires_grad=True)\n",
    "weight_2 = torch.randn(dimensions[-1], dimensions[1], requires_grad=True)"
   ],
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T20:27:33.343406Z",
     "start_time": "2024-07-14T20:27:33.340339Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bias_1 = torch.randn(dimensions[1], batch_size, requires_grad=True)\n",
    "bias_2 = torch.randn(dimensions[-1], batch_size, requires_grad=True)"
   ],
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Implement feed forward"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Implement the feed forward algorithm for both layers using matrix multiplication (`torch.mm()`), assume relu as the activation function (`torch.relu()`)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "output n = `activation_function`(weights n-1 * output n-1)"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T20:27:35.316Z",
     "start_time": "2024-07-14T20:27:35.311909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "multi_1 = torch.mm(weight_1, X) + bias_1\n",
    "A1 = torch.relu(multi_1)\n",
    "multi_2 = torch.mm(weight_2, A1) + bias_2\n",
    "A2 = torch.relu(multi_2)"
   ],
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T20:17:43.231512Z",
     "start_time": "2024-07-14T20:17:43.226286Z"
    }
   },
   "cell_type": "code",
   "source": "A2.shape",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 64])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Implement backpropagation"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Calculate the loss function"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Use mean square error as the loss function (MSE)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "$$ loss = (y - \\hat{y})^2 $$"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Remember that the result of the error function should be a scalar - use the `.mean()` function on the tensor to average the results across all predictions"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T20:27:39.294626Z",
     "start_time": "2024-07-14T20:27:39.291539Z"
    }
   },
   "cell_type": "code",
   "source": "loss = ((y - A2) ** 2).mean()",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T20:17:46.979299Z",
     "start_time": "2024-07-14T20:17:46.974193Z"
    }
   },
   "cell_type": "code",
   "source": "loss",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15412.4688, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Calculate gradients"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T20:27:41.646258Z",
     "start_time": "2024-07-14T20:27:41.642648Z"
    }
   },
   "cell_type": "code",
   "source": "loss.backward()",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Update weight values based on multiple gradients.\n",
    "Use lr 5e-6."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T20:17:50.966859Z",
     "start_time": "2024-07-14T20:17:50.963248Z"
    }
   },
   "cell_type": "code",
   "source": "lr = 5e-6",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T20:27:45.395385Z",
     "start_time": "2024-07-14T20:27:45.391256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with torch.no_grad():\n",
    "    weight_1 -= lr * weight_1.grad\n",
    "    weight_2 -= lr * weight_2.grad\n",
    "    bias_1 -= lr * bias_1.grad\n",
    "    bias_2 -= lr * bias_2.grad\n",
    "    \n",
    "    # Manually zero the gradients after updating the weights\n",
    "    weight_1.grad.zero_()\n",
    "    weight_2.grad.zero_()\n",
    "    bias_1.grad.zero_()\n",
    "    bias_2.grad.zero_()\n"
   ],
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Implement training loop"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "repeat feedforward operations and backpropagation for 600 epoches."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T20:27:49.389241Z",
     "start_time": "2024-07-14T20:27:49.386172Z"
    }
   },
   "cell_type": "code",
   "source": "epochs = 600",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T20:27:50.037578Z",
     "start_time": "2024-07-14T20:27:50.032974Z"
    }
   },
   "cell_type": "code",
   "source": [
    "weight_1 = torch.randn(dimensions[1], dimensions[0], requires_grad=True)\n",
    "weight_2 = torch.randn(dimensions[-1], dimensions[1], requires_grad=True)\n",
    "bias_1 = torch.randn(dimensions[1], batch_size, requires_grad=True)\n",
    "bias_2 = torch.randn(dimensions[-1], batch_size,requires_grad=True)"
   ],
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T20:27:51.464079Z",
     "start_time": "2024-07-14T20:27:50.991012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for epoch in range(epochs):\n",
    "    multi_1 = torch.mm(weight_1, X) + bias_1\n",
    "    A1 = torch.relu(multi_1)\n",
    "    multi_2 = torch.mm(weight_2, A1) + bias_2\n",
    "    A2 = torch.relu(multi_2)\n",
    "    \n",
    "    loss = ((y - A2) ** 2).mean()\n",
    "    loss.backward()\n",
    "    \n",
    "    if epoch % 50 == 0:\n",
    "        print(loss)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        weight_1 -= lr * weight_1.grad\n",
    "        weight_2 -= lr * weight_2.grad\n",
    "        bias_1 -= lr * bias_1.grad\n",
    "        bias_2 -= lr * bias_2.grad\n",
    "        \n",
    "        weight_1.grad.zero_()\n",
    "        weight_2.grad.zero_()\n",
    "        bias_1.grad.zero_()\n",
    "        bias_2.grad.zero_()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9078.7207, grad_fn=<MeanBackward0>)\n",
      "tensor(5319.8291, grad_fn=<MeanBackward0>)\n",
      "tensor(3398.5259, grad_fn=<MeanBackward0>)\n",
      "tensor(2313.4373, grad_fn=<MeanBackward0>)\n",
      "tensor(1654.3785, grad_fn=<MeanBackward0>)\n",
      "tensor(1229.1711, grad_fn=<MeanBackward0>)\n",
      "tensor(938.8338, grad_fn=<MeanBackward0>)\n",
      "tensor(733.0504, grad_fn=<MeanBackward0>)\n",
      "tensor(582.1727, grad_fn=<MeanBackward0>)\n",
      "tensor(468.0153, grad_fn=<MeanBackward0>)\n",
      "tensor(380.4975, grad_fn=<MeanBackward0>)\n",
      "tensor(312.0228, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "execution_count": 57
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
